{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wfdb\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import msgpack\n",
    "import scipy.stats as stats\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlist = []\n",
    "records = os.path.normpath('mit-bih-raw/RECORDS')\n",
    "with open(records) as rfile:\n",
    "    for record in rfile:\n",
    "        record = record[0:len(record)-1] # Remove any erronious new line characters at the end ('\\n')\n",
    "        rlist.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd22a80b2b8b4404ae1b02ad38b6e77a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampto must be greater than sampfrom\n",
      "sampto must be greater than sampfrom\n"
     ]
    }
   ],
   "source": [
    "samples = [] # will house the samples of all subjects\n",
    "good_list = [] # will list the names of the subjects we successfully extracted\n",
    "bad_list = [] # will house the names of the subjects we failed to extract\n",
    "qrs = [] # will house the indices of R-Peaks for all subjects\n",
    "atr_label = [] # will house the labels for each rhythm annotation for all subjects\n",
    "atr_locs = [] # will house the locations corresponding to the rhythm annotation labels\n",
    "\n",
    "for x in tqdm(rlist): #this will iterate through te records that we found above\n",
    "    try:\n",
    "        samp = wfdb.rdsamp(os.path.normpath('mit-bih-raw/'+x)) # wfdb._____(file_location) will read the signal & header data and return a 2 value array\n",
    "            # samp[0] - the signal data is the raw reading from the ecg. Each value is a sample taken.\n",
    "            # samp[1] - the header data includes things about the signal data such as:\n",
    "              # samples per section, denoted 'fs'\n",
    "              # number of signals, denoted 'n_sig'\n",
    "        ######################################################\n",
    "        samples.append(samp) #add it to our array for all subject\n",
    "        \n",
    "            #What is our file extension that has the annotation we want? Find it here and replace _____ with it \n",
    "            #hint: READ THE VARIABLE NAMES!!!!\n",
    "        qrs_tmp = wfdb.rdann(os.path.normpath('mit-bih-raw/'+x), extension=\"qrs\") #extract the QRS Info\n",
    "        qrs_locs = np.array(qrs_tmp.sample, dtype='int') #Get just the loccation of R-Peaks from the QRS Info\n",
    "        qrs.append(qrs_locs) # Add to our array for all subjects\n",
    "        \n",
    "            #Do the same thing here\n",
    "        atr = wfdb.rdann(os.path.normpath('mit-bih-raw/'+x),extension=\"atr\") #extract the atr info which stores the rhythm type(s) over the whole signal\n",
    "        atr_label.append(atr.aux_note) # aux_note stores the type of rhythm - main two are '(N' for normal and '(AFIB' for AFIB\n",
    "        atr_locs.append(np.append(atr.sample, len(samp[0]))) #I add the length of the whole sample to the end for better visualization later\n",
    "        \n",
    "        good_list.append(x) # when all extraction is successful append the record name to good_list\n",
    "    except Exception as exep:\n",
    "        tqdm.write(str(exep)) # Alert the user of an exception\n",
    "        bad_list.append(x) # add to the bad list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "atr_dics = [] #Initialize the array that will hold the dictionary for each subject\n",
    "\n",
    "for idxs,lab in enumerate(atr_label):\n",
    "    atr_dic = {} #Initialize dictionary for each subject\n",
    "    for idx,x in enumerate(lab):\n",
    "        if x not in atr_dic.keys():\n",
    "            atr_dic[x] = [] #Add dictionary key if does not exist\n",
    "        atr_dic[x].append([atr_locs[idxs][idx], atr_locs[idxs][idx+1]]) #Insert range for each rhythm\n",
    "    atr_dics.append(atr_dic) #Add to dictionary array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520c8b5f04c344698ac4cf022a5b9465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_dfs = {} # Initialize the subject_dataframes - will hold all of our subject dataframes\n",
    "\n",
    "for s, _ in enumerate(tqdm(good_list)): # Iterate through all of the subjects that we have complete data of \n",
    "    subj = pd.DataFrame( # The below statements initialize our datafram. The first to columns will be our given signals, and the rest we initialize to 0\n",
    "        data = np.transpose(np.array([ # First we give our data, for pandas they want the data by row instead of by column, so we use transpose to get the proper format\n",
    "                                               [x[0] for x in samples[s][0]],\n",
    "                                               [x[1] for x in samples[s][0]],\n",
    "                                               np.zeros(len(samples[s][0])), # np.zeros makes an array of zeros with the given lenth\n",
    "                                               np.zeros(len(samples[s][0])), \n",
    "                                               np.zeros(len(samples[s][0])), \n",
    "                                               np.zeros(len(samples[s][0])), \n",
    "                                        ])\n",
    "                           ),\n",
    "        columns = ['Signal 1', 'Signal 2', 'R-Peak', 'Normal', 'AFIB', 'Other'] # Here we name our columns to match the dataframe we outlined above\n",
    "    )\n",
    "    norm = [] # Initialize the norm array which will list every index the person is in a normal rhythm\n",
    "    if '(N' in atr_dics[s].keys():\n",
    "        for x in atr_dics[s]['(N']: # Then we iterate through our ranges we extracted above\n",
    "            norm = norm + list(range(x[0], x[1])) # And add all values in the range to our norm array\n",
    "    af = [] # Then we do the same steps above for AFIB rhythms\n",
    "    if '(AFIB' in atr_dics[s].keys():\n",
    "        for x in atr_dics[s]['(AFIB']:\n",
    "            af = af + list(range(x[0], x[1]))\n",
    "    subj['R-Peak']= subj.index.isin(qrs[s]) # the isin() function of a DataFram index will return true if the index is in that list and false if it is not\n",
    "                                            # then, we can initialize our dataFrame with correct values based on that\n",
    "    subj['Normal']= subj.index.isin(norm)\n",
    "    subj['AFIB'] = subj.index.isin(af)\n",
    "    subj['Other'] = ~subj.index.isin(np.append(norm, af)) # Because we are classifying AFIB specifically we define other as any rhythm not in the norm or AFIB list\n",
    "    \n",
    "    full_dfs[_] = subj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7e96a32e544421b3243be3a638faad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not os.path.exists('mit-bih-dataframes/'):\n",
    "    os.mkdir('mit-bih-dataframes/')\n",
    "\n",
    "for idx, x in enumerate(tqdm(good_list)): \n",
    "    if not os.path.exists('mit-bih-dataframes/'+x+ '.parquet') or reload_flag:\n",
    "        full_dfs[x].to_parquet(os.path.normpath('mit-bih-dataframes/'+x+'.parquet'))\n",
    "\n",
    "np.savetxt(os.path.normpath(\"mit-bih-dataframes/subject_list.csv\"), good_list, delimiter=\",\",  fmt='%s') \n",
    "   # We'll load the complete list of subjects as well so that we can easily recreate the file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab19743cd41b4a4ca4889d12c3b3561b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not os.path.exists('mit-bih-extracted/'):\n",
    "    os.mkdir('mit-bih-extracted/')\n",
    "\n",
    "def encoder(obj):\n",
    "    if isinstance(obj, datetime.time):\n",
    "        return {'__datetime__': True, 'as_str': obj.strftime(\"%H:%M:%S.%f\")}\n",
    "    if isinstance(obj, np.int64):\n",
    "        return {'__npint64__': True, 'as_int': int(obj)}\n",
    "    return obj\n",
    "\n",
    "np.savetxt(\"mit-bih-extracted/subject_list.csv\", good_list, delimiter=\",\",  fmt='%s')\n",
    "for idx, x in enumerate(tqdm(good_list)):\n",
    "    if not os.path.exists(\"mit-bih-extracted/\"+x+\"_signals.parquet\") or reload_flag:\n",
    "        signaldf = pd.DataFrame(np.array(samples[idx][0]), columns=[\"signal1\", \"signal2\"])\n",
    "        signaldf.to_parquet(os.path.normpath(\"mit-bih-extracted/\"+x+\"_signals.parquet\"))\n",
    "    if not os.path.exists(\"mit-bih-extracted/\"+x+\"_rpeaks.parquet\") or reload_flag:\n",
    "        rpeaksdf = pd.DataFrame(np.array(qrs[idx]), columns=[\"rpeaks\"])\n",
    "        rpeaksdf.to_parquet(os.path.normpath(\"mit-bih-extracted/\"+x+\"_rpeaks.parquet\"))\n",
    "    if not os.path.exists(\"mit-bih-extracted/\"+x+\"_headers.msgpack\") or reload_flag:\n",
    "        with open(os.path.normpath(\"mit-bih-extracted/\"+x+\"_headers.msgpack\"), 'wb') as outfile:\n",
    "            outfile.write(msgpack.packb(samples[idx][1], default=encoder))\n",
    "    if not os.path.exists(\"mit-bih-extracted/\"+x+\"_rhythms.msgpack\") or reload_flag:\n",
    "        with open(os.path.normpath(\"mit-bih-extracted/\"+x+\"_rhythms.msgpack\"), 'wb') as outfile:\n",
    "            outfile.write(msgpack.packb(atr_dics[idx], default=encoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e46645794e2747bfb98fefc2a4dba480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rlist = good_list\n",
    "\n",
    "rpeak_dfs = {}\n",
    "for record in tqdm(rlist):\n",
    "    df = pd.read_parquet(os.path.normpath('mit-bih-extracted/'+record+'_rpeaks.parquet'))\n",
    "    rhythms = full_dfs[record].filter(items = df['rpeaks'], axis=0).reset_index(drop=True)[['Normal', 'AFIB', 'Other']]\n",
    "\n",
    "    df = pd.concat([df, rhythms], axis=1)\n",
    "\n",
    "    rpeak_dfs[record] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rmean(rrInts):\n",
    "    rr_arr = rrInts.values\n",
    "    rmeans = []\n",
    "    for index, value in enumerate(rr_arr):\n",
    "        if index==0:\n",
    "            rmeans.append(value)\n",
    "        else:\n",
    "            rmeans.append(0.75*rmeans[index-1] + 0.25*value)\n",
    "    \n",
    "    return rmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_diff(rrInts):\n",
    "    rr_arr = rrInts.values\n",
    "    diffs = [0]\n",
    "    for idx, rrInt in enumerate(rrInts):\n",
    "        if idx>0:\n",
    "            diffs.append(np.abs(rrInt-rrInts[idx-1]))\n",
    "    return diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rr_int_df(rpeaks, full_df):\n",
    "    raw = pd.DataFrame(data={'rr_int': rpeaks['rpeaks'].diff().dropna()})\n",
    "    filtered = raw.drop(raw[raw.rr_int > 500].index).reset_index(drop=True)\n",
    "\n",
    "    filtered['rmean'] = extract_rmean(filtered['rr_int'])\n",
    "    filtered['diff'] = extract_diff(filtered['rr_int'])\n",
    "    filtered['sqr_diff'] = filtered['diff']**2\n",
    "\n",
    "    def rhythm_finder(row):\n",
    "        if row['Normal']:\n",
    "            return 'N'\n",
    "        elif row['AFIB']:\n",
    "            return 'A'\n",
    "        else:\n",
    "            return 'O'\n",
    "    filtered['rhythm'] = rpeaks.apply(rhythm_finder, axis=1)\n",
    "\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd6d1bffb8264862a96c706e4fd80775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rr_int_dfs = {}\n",
    "for record in tqdm(rlist):\n",
    "    rr_int_dfs[record] = rr_int_df(rpeak_dfs[record], full_dfs[record])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b61111f5a44dfe9fbd4e1cef7d4f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not os.path.exists('mit-bih-rr-intervals/'):\n",
    "    os.mkdir('mit-bih-rr-intervals/')\n",
    "\n",
    "for record in tqdm(rlist): \n",
    "    if not os.path.exists('mit-bih-dataframes/'+record+'.parquet') or reload_flag:\n",
    "        rr_int_dfs[record].to_parquet(os.path.normpath('mit-bih-rr-intervals/'+record+'.parquet'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ada57d62bdba33f60f3d98aec0dc1db90359aaf5574901473d57c7ef0e255730"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
