{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d441cb",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 3.698932,
     "end_time": "2023-02-25T02:20:14.724643",
     "exception": false,
     "start_time": "2023-02-25T02:20:11.025711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "from pathlib import Path, PurePath\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pickle\n",
    "from joblib import Parallel, delayed, dump, load\n",
    "from shutil import rmtree\n",
    "from collections import defaultdict\n",
    "\n",
    "import timeit\n",
    "\n",
    "import matplotlib_inline.backend_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\"retina\")\n",
    "\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import catboost as cb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b7a70d",
   "metadata": {
    "papermill": {
     "duration": 0.024087,
     "end_time": "2023-02-25T02:20:14.753785",
     "exception": false,
     "start_time": "2023-02-25T02:20:14.729698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rlist = []\n",
    "records = PurePath(Path(os.getcwd()).parents[1], Path('/Users/taran/Documents/GitHub/2022-svsm-afib-group1/mit-bih-dataframes-stepping/subject_list.csv'))\n",
    "with open(records) as rfile:\n",
    "    recordreader = csv.reader(rfile, delimiter=' ', quotechar='|')\n",
    "    for row in recordreader:\n",
    "        rlist.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6159637a-f4e0-47d9-8111-3d4d8ceeed40",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_weight = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc492292",
   "metadata": {
    "papermill": {
     "duration": 1.290393,
     "end_time": "2023-02-25T02:20:16.047768",
     "exception": false,
     "start_time": "2023-02-25T02:20:14.757375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_dfs = {}\n",
    "for record in tqdm(rlist):\n",
    "    feature_dfs[record] = pd.read_parquet(str(Path(os.getcwd()).parents[1]) + '/GitHub/2022-svsm-afib-group1/mit-bih-time-features-stepping/'+record+'.parquet')\n",
    "\n",
    "combined_features = pd.concat([feature_dfs[key][1:] for key in feature_dfs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7bfc92",
   "metadata": {
    "papermill": {
     "duration": 0.105087,
     "end_time": "2023-02-25T02:20:16.157453",
     "exception": false,
     "start_time": "2023-02-25T02:20:16.052366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = combined_features[['StoS', 'StoR', 'StoL', 'RtoS', 'RtoR', 'RtoL', 'LtoS', 'LtoR', 'LtoL', 'std', 'cov', 'range', 'rrInt_var', 'rmean_var', 'rmssd', 'mad', 'iqr','entropy','approx_entropy']]#, 'drrmean', 'drrvar']]\n",
    "y = combined_features['mappedLabel'].map({\"Non-Afib\": 0, \"Afib\": 1})\n",
    "groups = combined_features['subjectID'].astype('int64')\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "splits = list(logo.split(X, y, groups=groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa3ff85",
   "metadata": {
    "papermill": {
     "duration": 0.013836,
     "end_time": "2023-02-25T02:20:16.175323",
     "exception": false,
     "start_time": "2023-02-25T02:20:16.161487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.seterr(all='ignore')\n",
    "moving_accs = []\n",
    "\n",
    "if os.path.exists(f'saved_results_stepping_{current_weight}')==False:\n",
    "    os.mkdir(f'saved_results_stepping_{current_weight}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54f2a18",
   "metadata": {
    "papermill": {
     "duration": 0.020048,
     "end_time": "2023-02-25T02:20:16.199212",
     "exception": false,
     "start_time": "2023-02-25T02:20:16.179164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def score_reporter(results, importances=True, moving_acc_plot=False, classifier_name=\"idk\"):\n",
    "    bestParams = None\n",
    "    maxScore = 0\n",
    "    for params, scores in results.items():\n",
    "        num_splits = scores['folds']\n",
    "        accuracy = [scores[f\"split{i}_accuracy\"] for i in range(num_splits)]\n",
    "        print(params, np.mean(accuracy))\n",
    "        \n",
    "        if (np.mean(accuracy) > maxScore):\n",
    "            bestParams = params\n",
    "            maxScore = np.mean(accuracy)\n",
    "            \n",
    "    bestScores = results[bestParams]\n",
    "    num_splits = bestScores['folds']\n",
    "    accuracy = [bestScores[f\"split{i}_accuracy\"] for i in range(num_splits)]\n",
    "    sensitivity = [bestScores[f\"split{i}_sensitivity\"] for i in range(num_splits)]\n",
    "    specificity = [bestScores[f\"split{i}_specificity\"] for i in range(num_splits)]\n",
    "    precision = [bestScores[f\"split{i}_precision\"] for i in range(num_splits)]\n",
    "    f1_score = [bestScores[f\"split{i}_f1_score\"] for i in range(num_splits)]\n",
    "    if importances:\n",
    "        feature_importances = [list(bestScores[f\"split{i}_feature_importances\"].values()) for i in range(num_splits)]\n",
    "    \n",
    "        avg_importances = np.mean(np.array(feature_importances), axis=0)\n",
    "        feature_names = list(bestScores[\"split0_feature_importances\"].keys())[0]\n",
    "        mapped_importances = {name: rank for name, rank in zip(feature_names, avg_importances.flatten())}\n",
    "        \n",
    "    if moving_acc_plot:\n",
    "        subject_accs = [bestScores[f\"split{i}_subject_acc\"] for i in range(num_splits)]\n",
    "        minLen = len(subject_accs[0])\n",
    "        for accs in subject_accs:\n",
    "            if len(accs)<minLen:\n",
    "                minLen = len(accs)\n",
    "\n",
    "        avg_list = [sum(sub_list) * 100 / len(sub_list) for sub_list in zip(*subject_accs)]\n",
    "        plt.plot(avg_list)\n",
    "        plt.title(classifier_name + \" Accuracy Over Time\")\n",
    "        plt.xlabel(\"Stepping windows elapsed\")\n",
    "        plt.ylabel(\"Average accuracy across CV folds (%)\")\n",
    "        plt.show()\n",
    "    \n",
    "    print(f\"The best parameters were {bestParams}\")\n",
    "    print(f\"Accuracy for each fold: {accuracy}\")\n",
    "    print(f\"Mean accuracy: {np.nanmean(accuracy)}\")\n",
    "    print(f\"Std accuracy: {np.nanstd(accuracy)}\")\n",
    "    print(f\"Sensitivity for each fold: {sensitivity}\")\n",
    "    print(f\"Mean sensitivity: {np.nanmean(sensitivity)}\")\n",
    "    print(f\"Std sensitivity: {np.nanstd(sensitivity)}\")\n",
    "    print(f\"Specificity for each fold: {specificity}\")\n",
    "    print(f\"Mean specificity: {np.nanmean(specificity)}\")\n",
    "    print(f\"Std specificity: {np.nanstd(specificity)}\")\n",
    "    print(f\"Precision for each fold: {precision}\")\n",
    "    print(f\"Mean precision: {np.nanmean(precision)}\")\n",
    "    print(f\"Std precision: {np.nanstd(precision)}\")\n",
    "    print(f\"F1-score for each fold: {f1_score}\")\n",
    "    print(f\"Mean F1-score: {np.nanmean(f1_score)}\")\n",
    "    print(f\"Std F1-score: {np.nanstd(f1_score)}\")\n",
    "    if importances:\n",
    "        print(\"Average feature importances: \")\n",
    "        print(mapped_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4978575c-5e37-4cfc-b5fa-4fc035a39582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_parallel(clf, X, y, train, test, **fit_params):\n",
    "    np.seterr(all='ignore')\n",
    "    \n",
    "    X_train = X.iloc[train]\n",
    "    y_train = y.iloc[train]\n",
    "\n",
    "    X_test = X.iloc[test]\n",
    "    y_test = y.iloc[test]\n",
    "    \n",
    "    cloned_clf = clone(clf)\n",
    "    cloned_clf.fit(X_train, y_train)\n",
    "\n",
    "    pred_values = cloned_clf.predict(X_test)\n",
    "    \n",
    "    total_seen = 0\n",
    "    total_correct = 0\n",
    "    subject_acc = []\n",
    "    for idx, pred in enumerate(pred_values):\n",
    "        total_seen+=1\n",
    "        if pred==y_test.iloc[idx]:\n",
    "            total_correct+=1\n",
    "        subject_acc.append(total_correct/total_seen)\n",
    "\n",
    "    cm = confusion_matrix(y_test.values.reshape(y_test.shape[0]), pred_values)\n",
    "    sensitivity = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "    specificity = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "    precision = (cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "\n",
    "    results_dict = {\n",
    "        \"accuracy\": accuracy_score(y_test, pred_values),\n",
    "        \"sensitivity\": sensitivity,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision,\n",
    "        \"f1_score\": (2*precision*sensitivity)/(precision+sensitivity),\n",
    "        \"subject_acc\": subject_acc\n",
    "    }\n",
    "    \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac2f2ab-b905-425d-b871-3669177de3f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit_xgboost_parallel(clf, X, y, train, test, **fit_params):\n",
    "    np.seterr(all='ignore')\n",
    "    \n",
    "    X_train = X.iloc[train]\n",
    "    y_train = y.iloc[train]\n",
    "\n",
    "    X_test = X.iloc[test]\n",
    "    y_test = y.iloc[test]\n",
    "    \n",
    "    cloned_clf = clone(clf)\n",
    "    cloned_clf.fit(X_train, y_train)\n",
    "\n",
    "    pred_values = cloned_clf.predict(X_test)\n",
    "    \n",
    "    total_seen = 0\n",
    "    total_correct = 0\n",
    "    subject_acc = []\n",
    "    for idx, pred in enumerate(pred_values):\n",
    "        total_seen+=1\n",
    "        if pred==y_test.iloc[idx]:\n",
    "            total_correct+=1\n",
    "        subject_acc.append(total_correct/total_seen)\n",
    "\n",
    "    cm = confusion_matrix(y_test.values.reshape(y_test.shape[0]), pred_values)\n",
    "    sensitivity = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "    specificity = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "    precision = (cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "\n",
    "    results_dict = {\n",
    "        \"accuracy\": accuracy_score(y_test, pred_values),\n",
    "        \"sensitivity\": sensitivity,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision,\n",
    "        \"f1_score\": (2*precision*sensitivity)/(precision+sensitivity),\n",
    "        \"feature_importances\": {A: B for A, B in zip(cloned_clf.feature_names_in_, cloned_clf.feature_importances_)},\n",
    "        \"subject_acc\": subject_acc\n",
    "    }\n",
    "    \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca40cd1-059d-4be9-96f2-8932e73923f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit_catboost_parallel(clf, X, y, train, test, **fit_params):\n",
    "    np.seterr(all='ignore')\n",
    "    \n",
    "    X_train = X.iloc[train]\n",
    "    y_train = y.iloc[train]\n",
    "\n",
    "    X_test = X.iloc[test]\n",
    "    y_test = y.iloc[test]\n",
    "    \n",
    "    cloned_clf = clone(clf)\n",
    "    cloned_clf.fit(X_train, y_train)\n",
    "\n",
    "    pred_values = cloned_clf.predict(X_test)\n",
    "    \n",
    "    total_seen = 0\n",
    "    total_correct = 0\n",
    "    subject_acc = []\n",
    "    for idx, pred in enumerate(pred_values):\n",
    "        total_seen+=1\n",
    "        if pred==y_test.iloc[idx]:\n",
    "            total_correct+=1\n",
    "        subject_acc.append(total_correct/total_seen)\n",
    "\n",
    "    cm = confusion_matrix(y_test.values.reshape(y_test.shape[0]), pred_values)\n",
    "    sensitivity = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "    specificity = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "    precision = (cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "\n",
    "    results_dict = {\n",
    "        \"accuracy\": accuracy_score(y_test, pred_values),\n",
    "        \"sensitivity\": sensitivity,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision,\n",
    "        \"f1_score\": (2*precision*sensitivity)/(precision+sensitivity),\n",
    "        \"feature_importances\": {A: B for A, B in zip(cloned_clf.feature_names_, cloned_clf.feature_importances_)},\n",
    "        \"subject_acc\": subject_acc\n",
    "    }\n",
    "    \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdc9289-0554-40a0-906a-1612251fe6d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit_lightgbm_parallel(clf, X, y, train, test, **fit_params):\n",
    "    np.seterr(all='ignore')\n",
    "    \n",
    "    X_train = X.iloc[train]\n",
    "    y_train = y.iloc[train]\n",
    "\n",
    "    X_test = X.iloc[test]\n",
    "    y_test = y.iloc[test]\n",
    "    \n",
    "    cloned_clf = clone(clf)\n",
    "    cloned_clf.fit(X_train,y_train,eval_set=[(X_test,y_test),(X_train,y_train)], \n",
    "                   eval_metric='logloss')\n",
    "\n",
    "    pred_values = cloned_clf.predict(X_test)\n",
    "    \n",
    "    total_seen = 0\n",
    "    total_correct = 0\n",
    "    subject_acc = []\n",
    "    for idx, pred in enumerate(pred_values):\n",
    "        total_seen+=1\n",
    "        if pred==y_test.iloc[idx]:\n",
    "            total_correct+=1\n",
    "        subject_acc.append(total_correct/total_seen)\n",
    "\n",
    "    cm = confusion_matrix(y_test.values.reshape(y_test.shape[0]), pred_values)\n",
    "    sensitivity = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "    specificity = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "    precision = (cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "\n",
    "    results_dict = {\n",
    "        \"accuracy\": accuracy_score(y_test, pred_values),\n",
    "        \"sensitivity\": sensitivity,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision,\n",
    "        \"f1_score\": (2*precision*sensitivity)/(precision+sensitivity),\n",
    "        \"feature_importances\": {A: B for A, B in zip(cloned_clf.feature_name_, cloned_clf.feature_importances_)},\n",
    "        \"subject_acc\": subject_acc\n",
    "    }\n",
    "    \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77db9518-c15a-4d53-b7dc-d6cf05df25eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "folder = './joblib_memmap'\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "dump(X, os.path.join(folder, 'X'))\n",
    "X_memmap = load(os.path.join(folder, 'X'), mmap_mode='r')\n",
    "dump(y, os.path.join(folder, 'y'))\n",
    "y_memmap = load(os.path.join(folder, 'y'), mmap_mode='r')\n",
    "\n",
    "#num_combinations = 30\n",
    "params = {\n",
    "    \"solver\": [\"liblinear\"]\n",
    "}\n",
    "param_grid = ParameterGrid(params)\n",
    "print(f'Fitting with {len(param_grid)} different parameter combinations')\n",
    "results = {}\n",
    "\n",
    "with tqdm(param_grid) as pbar:\n",
    "    for fit_params in pbar:\n",
    "        pbar.set_description(f'Fitting parameter combination: {fit_params}')\n",
    "        \n",
    "        clf = LogisticRegression(max_iter=3000,\n",
    "                                 **fit_params)\n",
    "        fold_results = Parallel(n_jobs=8)(\n",
    "            delayed(fit_parallel)(clf, X_memmap, y_memmap, train, test, **fit_params)\n",
    "            for (train, test) in splits\n",
    "        )\n",
    "        \n",
    "        current_results = {}\n",
    "        for i, result in enumerate(fold_results):\n",
    "            current_results[f\"split{i}_accuracy\"] = result[\"accuracy\"]\n",
    "            current_results[f\"split{i}_sensitivity\"] = result[\"sensitivity\"]\n",
    "            current_results[f\"split{i}_specificity\"] = result[\"specificity\"]\n",
    "            current_results[f\"split{i}_precision\"] = result[\"precision\"]\n",
    "            current_results[f\"split{i}_f1_score\"] = result[\"f1_score\"]\n",
    "            current_results[f\"split{i}_subject_acc\"] = result[\"subject_acc\"]\n",
    "        results[tuple(sorted(fit_params.items()))] = current_results\n",
    "        results[tuple(sorted(fit_params.items()))]['folds'] = len(splits)\n",
    "\n",
    "with open(f'saved_results_stepping_{current_weight}/lr_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712770d8-e73b-4acc-a88d-7432e3d23a4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "score_reporter(results, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22095e6-daf3-46cd-8ab0-2ec9edc32e1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LDA\n",
    "folder = './joblib_memmap'\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "dump(X, os.path.join(folder, 'X'))\n",
    "X_memmap = load(os.path.join(folder, 'X'), mmap_mode='r')\n",
    "dump(y, os.path.join(folder, 'y'))\n",
    "y_memmap = load(os.path.join(folder, 'y'), mmap_mode='r')\n",
    "\n",
    "#num_combinations = 30\n",
    "params = {\n",
    "    \"solver\": [\"lsqr\"]\n",
    "}\n",
    "param_grid = ParameterGrid(params)\n",
    "print(f'Fitting with {len(param_grid)} different parameter combinations')\n",
    "results = {}\n",
    "\n",
    "with tqdm(param_grid) as pbar:\n",
    "    for fit_params in pbar:\n",
    "        pbar.set_description(f'Fitting parameter combination: {fit_params}')\n",
    "        \n",
    "        clf = LinearDiscriminantAnalysis(**fit_params)\n",
    "        fold_results = Parallel(n_jobs=8)(\n",
    "            delayed(fit_parallel)(clf, X_memmap, y_memmap, train, test, **fit_params)\n",
    "            for (train, test) in splits\n",
    "        )\n",
    "        \n",
    "        current_results = {}\n",
    "        for i, result in enumerate(fold_results):\n",
    "            current_results[f\"split{i}_accuracy\"] = result[\"accuracy\"]\n",
    "            current_results[f\"split{i}_sensitivity\"] = result[\"sensitivity\"]\n",
    "            current_results[f\"split{i}_specificity\"] = result[\"specificity\"]\n",
    "            current_results[f\"split{i}_precision\"] = result[\"precision\"]\n",
    "            current_results[f\"split{i}_f1_score\"] = result[\"f1_score\"]\n",
    "            current_results[f\"split{i}_subject_acc\"] = result[\"subject_acc\"]\n",
    "        results[tuple(sorted(fit_params.items()))] = current_results\n",
    "        results[tuple(sorted(fit_params.items()))]['folds'] = len(splits)\n",
    "\n",
    "with open(f'saved_results_stepping_{current_weight}/lda_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4067b5b5-fbf0-4c28-bd41-7f76d78d036f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "score_reporter(results, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbc6551-0cd6-4c0b-8712-30b054877be9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# QDA\n",
    "folder = './joblib_memmap'\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "dump(X, os.path.join(folder, 'X'))\n",
    "X_memmap = load(os.path.join(folder, 'X'), mmap_mode='r')\n",
    "dump(y, os.path.join(folder, 'y'))\n",
    "y_memmap = load(os.path.join(folder, 'y'), mmap_mode='r')\n",
    "\n",
    "#num_combinations = 30\n",
    "params = {\n",
    "    \"fake\": [\"param\"]\n",
    "}\n",
    "param_grid = ParameterGrid(params)\n",
    "print(f'Fitting with {len(param_grid)} different parameter combinations')\n",
    "results = {}\n",
    "\n",
    "with tqdm(param_grid) as pbar:\n",
    "    for fit_params in pbar:\n",
    "        pbar.set_description(f'Fitting parameter combination: {fit_params}')\n",
    "        \n",
    "        clf = QuadraticDiscriminantAnalysis()\n",
    "        fold_results = Parallel(n_jobs=8)(\n",
    "            delayed(fit_parallel)(clf, X_memmap, y_memmap, train, test, **fit_params)\n",
    "            for (train, test) in splits\n",
    "        )\n",
    "        \n",
    "        current_results = {}\n",
    "        for i, result in enumerate(fold_results):\n",
    "            current_results[f\"split{i}_accuracy\"] = result[\"accuracy\"]\n",
    "            current_results[f\"split{i}_sensitivity\"] = result[\"sensitivity\"]\n",
    "            current_results[f\"split{i}_specificity\"] = result[\"specificity\"]\n",
    "            current_results[f\"split{i}_precision\"] = result[\"precision\"]\n",
    "            current_results[f\"split{i}_f1_score\"] = result[\"f1_score\"]\n",
    "            current_results[f\"split{i}_subject_acc\"] = result[\"subject_acc\"]\n",
    "        results[tuple(sorted(fit_params.items()))] = current_results\n",
    "        results[tuple(sorted(fit_params.items()))]['folds'] = len(splits)\n",
    "\n",
    "with open(f'saved_results_stepping_{current_weight}/qda_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7070378-f6e4-4c65-98dd-c696a504a5cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "score_reporter(results, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ea3294-7b77-4796-b149-d71236a6da49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# KNN\n",
    "folder = './joblib_memmap'\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "dump(X, os.path.join(folder, 'X'))\n",
    "X_memmap = load(os.path.join(folder, 'X'), mmap_mode='r')\n",
    "dump(y, os.path.join(folder, 'y'))\n",
    "y_memmap = load(os.path.join(folder, 'y'), mmap_mode='r')\n",
    "\n",
    "#num_combinations = 30\n",
    "params = {\n",
    "    \"n_neighbors\": [9]\n",
    "}\n",
    "param_grid = ParameterGrid(params)\n",
    "print(f'Fitting with {len(param_grid)} different parameter combinations')\n",
    "results = {}\n",
    "\n",
    "with tqdm(param_grid) as pbar:\n",
    "    for fit_params in pbar:\n",
    "        pbar.set_description(f'Fitting parameter combination: {fit_params}')\n",
    "        \n",
    "        clf = KNeighborsClassifier(**fit_params)\n",
    "        fold_results = Parallel(n_jobs=8)(\n",
    "            delayed(fit_parallel)(clf, X_memmap, y_memmap, train, test, **fit_params)\n",
    "            for (train, test) in splits\n",
    "        )\n",
    "        \n",
    "        current_results = {}\n",
    "        for i, result in enumerate(fold_results):\n",
    "            current_results[f\"split{i}_accuracy\"] = result[\"accuracy\"]\n",
    "            current_results[f\"split{i}_sensitivity\"] = result[\"sensitivity\"]\n",
    "            current_results[f\"split{i}_specificity\"] = result[\"specificity\"]\n",
    "            current_results[f\"split{i}_precision\"] = result[\"precision\"]\n",
    "            current_results[f\"split{i}_f1_score\"] = result[\"f1_score\"]\n",
    "            current_results[f\"split{i}_subject_acc\"] = result[\"subject_acc\"]\n",
    "        results[tuple(sorted(fit_params.items()))] = current_results\n",
    "        results[tuple(sorted(fit_params.items()))]['folds'] = len(splits)\n",
    "\n",
    "with open(f'saved_results_stepping_{current_weight}/knn_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e1fced-c1c1-4f39-95f0-a9afe36191d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "score_reporter(results, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06af1de2-de9c-4306-8f77-87b971085597",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Decision tree\n",
    "folder = './joblib_memmap'\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "dump(X, os.path.join(folder, 'X'))\n",
    "X_memmap = load(os.path.join(folder, 'X'), mmap_mode='r')\n",
    "dump(y, os.path.join(folder, 'y'))\n",
    "y_memmap = load(os.path.join(folder, 'y'), mmap_mode='r')\n",
    "\n",
    "#num_combinations = 30\n",
    "params = {\n",
    "    \"max_depth\": [None]\n",
    "}\n",
    "param_grid = ParameterGrid(params)\n",
    "print(f'Fitting with {len(param_grid)} different parameter combinations')\n",
    "results = {}\n",
    "\n",
    "with tqdm(param_grid) as pbar:\n",
    "    for fit_params in pbar:\n",
    "        pbar.set_description(f'Fitting parameter combination: {fit_params}')\n",
    "        \n",
    "        clf = DecisionTreeClassifier(**fit_params)\n",
    "        \n",
    "        fold_results = []\n",
    "        for (train, test) in tqdm(splits, leave=False):\n",
    "            X_train = X.iloc[train]\n",
    "            y_train = y.iloc[train]\n",
    "\n",
    "            X_test = X.iloc[test]\n",
    "            y_test = y.iloc[test]\n",
    "\n",
    "            cloned_clf = clone(clf)\n",
    "            cloned_clf.fit(X_train, y_train)\n",
    "\n",
    "            pred_values = cloned_clf.predict(X_test)\n",
    "    \n",
    "            total_seen = 0\n",
    "            total_correct = 0\n",
    "            subject_acc = []\n",
    "            for idx, pred in enumerate(pred_values):\n",
    "                total_seen+=1\n",
    "                if pred==y_test.iloc[idx]:\n",
    "                    total_correct+=1\n",
    "                subject_acc.append(total_correct/total_seen)\n",
    "\n",
    "            cm = confusion_matrix(y_test.values.reshape(y_test.shape[0]), pred_values)\n",
    "            sensitivity = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "            specificity = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "            precision = (cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "\n",
    "            results_dict = {\n",
    "                \"accuracy\": accuracy_score(y_test, pred_values),\n",
    "                \"sensitivity\": sensitivity,\n",
    "                \"specificity\": specificity,\n",
    "                \"precision\": precision,\n",
    "                \"f1_score\": (2*precision*sensitivity)/(precision+sensitivity),\n",
    "                \"subject_acc\": subject_acc\n",
    "            }\n",
    "\n",
    "            fold_results.append(results_dict)\n",
    "        \n",
    "        current_results = {}\n",
    "        for i, result in enumerate(fold_results):\n",
    "            current_results[f\"split{i}_accuracy\"] = result[\"accuracy\"]\n",
    "            current_results[f\"split{i}_sensitivity\"] = result[\"sensitivity\"]\n",
    "            current_results[f\"split{i}_specificity\"] = result[\"specificity\"]\n",
    "            current_results[f\"split{i}_precision\"] = result[\"precision\"]\n",
    "            current_results[f\"split{i}_f1_score\"] = result[\"f1_score\"]\n",
    "            current_results[f\"split{i}_subject_acc\"] = result[\"subject_acc\"]\n",
    "        results[tuple(sorted(fit_params.items()))] = current_results\n",
    "        results[tuple(sorted(fit_params.items()))]['folds'] = len(splits)\n",
    "\n",
    "with open(f'saved_results_stepping_{current_weight}/dt_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d64dff9-9f28-440d-9a2a-b8c76148b2eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "score_reporter(results, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5e6676-c3d3-4a26-b0b8-88b50c1f599a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "folder = './joblib_memmap'\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "dump(X, os.path.join(folder, 'X'))\n",
    "X_memmap = load(os.path.join(folder, 'X'), mmap_mode='r')\n",
    "dump(y, os.path.join(folder, 'y'))\n",
    "y_memmap = load(os.path.join(folder, 'y'), mmap_mode='r')\n",
    "\n",
    "#num_combinations = 30\n",
    "params = {\n",
    "    \"n_estimators\": [300],\n",
    "    \"max_depth\": [30]\n",
    "}\n",
    "param_grid = ParameterGrid(params)\n",
    "print(f'Fitting with {len(param_grid)} different parameter combinations')\n",
    "results = {}\n",
    "\n",
    "with tqdm(param_grid) as pbar:\n",
    "    for fit_params in pbar:\n",
    "        pbar.set_description(f'Fitting parameter combination: {fit_params}')\n",
    "        \n",
    "        clf = RandomForestClassifier(**fit_params)\n",
    "        \n",
    "        fold_results = []\n",
    "        for (train, test) in tqdm(splits, leave=False):\n",
    "            X_train = X.iloc[train]\n",
    "            y_train = y.iloc[train]\n",
    "\n",
    "            X_test = X.iloc[test]\n",
    "            y_test = y.iloc[test]\n",
    "\n",
    "            cloned_clf = clone(clf)\n",
    "            cloned_clf.fit(X_train.astype(np.float32), y_train.astype(np.float32))\n",
    "\n",
    "            pred_values = cloned_clf.predict(X_test)\n",
    "    \n",
    "            total_seen = 0\n",
    "            total_correct = 0\n",
    "            subject_acc = []\n",
    "            for idx, pred in enumerate(pred_values):\n",
    "                total_seen+=1\n",
    "                if pred==y_test.iloc[idx]:\n",
    "                    total_correct+=1\n",
    "                subject_acc.append(total_correct/total_seen)\n",
    "\n",
    "            cm = confusion_matrix(y_test.values.reshape(y_test.shape[0]), pred_values)\n",
    "            sensitivity = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "            specificity = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "            precision = (cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "\n",
    "            results_dict = {\n",
    "                \"accuracy\": accuracy_score(y_test, pred_values),\n",
    "                \"sensitivity\": sensitivity,\n",
    "                \"specificity\": specificity,\n",
    "                \"precision\": precision,\n",
    "                \"f1_score\": (2*precision*sensitivity)/(precision+sensitivity),\n",
    "                \"subject_acc\": subject_acc\n",
    "            }\n",
    "\n",
    "            fold_results.append(results_dict)\n",
    "        \n",
    "        current_results = {}\n",
    "        for i, result in enumerate(fold_results):\n",
    "            current_results[f\"split{i}_accuracy\"] = result[\"accuracy\"]\n",
    "            current_results[f\"split{i}_sensitivity\"] = result[\"sensitivity\"]\n",
    "            current_results[f\"split{i}_specificity\"] = result[\"specificity\"]\n",
    "            current_results[f\"split{i}_precision\"] = result[\"precision\"]\n",
    "            current_results[f\"split{i}_f1_score\"] = result[\"f1_score\"]\n",
    "            current_results[f\"split{i}_subject_acc\"] = result[\"subject_acc\"]\n",
    "        results[tuple(sorted(fit_params.items()))] = current_results\n",
    "        results[tuple(sorted(fit_params.items()))]['folds'] = len(splits)\n",
    "\n",
    "with open(f'saved_results_stepping_{current_weight}/rf_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd4c1ca-dde4-4b2a-8a71-ff32d09b3f19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "score_reporter(results, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea1d458-c374-4aa5-9580-db049b126f8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# AdaBoost\n",
    "folder = './joblib_memmap'\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "dump(X, os.path.join(folder, 'X'))\n",
    "X_memmap = load(os.path.join(folder, 'X'), mmap_mode='r')\n",
    "dump(y, os.path.join(folder, 'y'))\n",
    "y_memmap = load(os.path.join(folder, 'y'), mmap_mode='r')\n",
    "\n",
    "#num_combinations = 30\n",
    "params = {\n",
    "    \"n_estimators\": [300]\n",
    "}\n",
    "param_grid = ParameterGrid(params)\n",
    "print(f'Fitting with {len(param_grid)} different parameter combinations')\n",
    "results = {}\n",
    "\n",
    "with tqdm(param_grid) as pbar:\n",
    "    for fit_params in pbar:\n",
    "        pbar.set_description(f'Fitting parameter combination: {fit_params}')\n",
    "        \n",
    "        clf = AdaBoostClassifier(algorithm=\"SAMME.R\",\n",
    "                                **fit_params)\n",
    "        fold_results = Parallel(n_jobs=4)(\n",
    "            delayed(fit_xgboost_parallel)(clf, X_memmap, y_memmap, train, test, **fit_params)\n",
    "            for (train, test) in splits\n",
    "        )\n",
    "        \n",
    "        current_results = {}\n",
    "        for i, result in enumerate(fold_results):\n",
    "            current_results[f\"split{i}_accuracy\"] = result[\"accuracy\"]\n",
    "            current_results[f\"split{i}_sensitivity\"] = result[\"sensitivity\"]\n",
    "            current_results[f\"split{i}_specificity\"] = result[\"specificity\"]\n",
    "            current_results[f\"split{i}_precision\"] = result[\"precision\"]\n",
    "            current_results[f\"split{i}_f1_score\"] = result[\"f1_score\"]\n",
    "            current_results[f\"split{i}_feature_importances\"] = result[\"feature_importances\"]\n",
    "            current_results[f\"split{i}_subject_acc\"] = result[\"subject_acc\"]\n",
    "        results[tuple(sorted(fit_params.items()))] = current_results\n",
    "        results[tuple(sorted(fit_params.items()))]['folds'] = len(splits)\n",
    "\n",
    "with open(f'saved_results_stepping_{current_weight}/ada_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52a866f-43d5-4276-9f1a-5a1382a1389f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "score_reporter(results, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46da264-3e41-4b8e-a668-94f630144eab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Gradient Boost\n",
    "folder = './joblib_memmap'\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "dump(X, os.path.join(folder, 'X'))\n",
    "X_memmap = load(os.path.join(folder, 'X'), mmap_mode='r')\n",
    "dump(y, os.path.join(folder, 'y'))\n",
    "y_memmap = load(os.path.join(folder, 'y'), mmap_mode='r')\n",
    "\n",
    "#num_combinations = 30\n",
    "params = {\n",
    "    \"n_estimators\": [350]\n",
    "}\n",
    "param_grid = ParameterGrid(params)\n",
    "print(f'Fitting with {len(param_grid)} different parameter combinations')\n",
    "results = {}\n",
    "\n",
    "with tqdm(param_grid) as pbar:\n",
    "    for fit_params in pbar:\n",
    "        pbar.set_description(f'Fitting parameter combination: {fit_params}')\n",
    "        \n",
    "        clf = GradientBoostingClassifier(loss=\"log_loss\",\n",
    "                                         max_depth=8,\n",
    "                                            **fit_params)\n",
    "        fold_results = Parallel(n_jobs=4)(\n",
    "            delayed(fit_xgboost_parallel)(clf, X_memmap, y_memmap, train, test, **fit_params)\n",
    "            for (train, test) in splits\n",
    "        )\n",
    "        \n",
    "        current_results = {}\n",
    "        for i, result in enumerate(fold_results):\n",
    "            current_results[f\"split{i}_accuracy\"] = result[\"accuracy\"]\n",
    "            current_results[f\"split{i}_sensitivity\"] = result[\"sensitivity\"]\n",
    "            current_results[f\"split{i}_specificity\"] = result[\"specificity\"]\n",
    "            current_results[f\"split{i}_precision\"] = result[\"precision\"]\n",
    "            current_results[f\"split{i}_f1_score\"] = result[\"f1_score\"]\n",
    "            current_results[f\"split{i}_feature_importances\"] = result[\"feature_importances\"]\n",
    "        results[tuple(sorted(fit_params.items()))] = current_results\n",
    "        results[tuple(sorted(fit_params.items()))]['folds'] = len(splits)\n",
    "\n",
    "with open(f'saved_results_stepping_{current_weight}/gb_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6f6d7b-36f0-45bc-be7d-6fd5d3376315",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# score_reporter(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b677a7d-c3d7-47e5-83e8-9e8035b78416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC\n",
    "folder = './joblib_memmap'\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "dump(X, os.path.join(folder, 'X'))\n",
    "X_memmap = load(os.path.join(folder, 'X'), mmap_mode='r')\n",
    "dump(y, os.path.join(folder, 'y'))\n",
    "y_memmap = load(os.path.join(folder, 'y'), mmap_mode='r')\n",
    "\n",
    "#num_combinations = 30\n",
    "params = {\n",
    "    #\"kernel\": [\"linear\", \"rbf\"]\n",
    "    \"verbose\": [False]\n",
    "}\n",
    "param_grid = ParameterGrid(params)\n",
    "print(f'Fitting with {len(param_grid)} different parameter combinations')\n",
    "results = {}\n",
    "\n",
    "with tqdm(param_grid) as pbar:\n",
    "    for fit_params in pbar:\n",
    "        pbar.set_description(f'Fitting parameter combination: {fit_params}')\n",
    "        \n",
    "        clf = LinearSVC(**fit_params)\n",
    "        \n",
    "        fold_results = []\n",
    "        for (train, test) in tqdm(splits, leave=False):\n",
    "            X_train = X.iloc[train]\n",
    "            y_train = y.iloc[train]\n",
    "\n",
    "            X_test = X.iloc[test]\n",
    "            y_test = y.iloc[test]\n",
    "\n",
    "            cloned_clf = clone(clf)\n",
    "            cloned_clf.fit(X_train, y_train)\n",
    "\n",
    "            pred_values = cloned_clf.predict(X_test)\n",
    "    \n",
    "            total_seen = 0\n",
    "            total_correct = 0\n",
    "            subject_acc = []\n",
    "            for idx, pred in enumerate(pred_values):\n",
    "                total_seen+=1\n",
    "                if pred==y_test.iloc[idx]:\n",
    "                    total_correct+=1\n",
    "                subject_acc.append(total_correct/total_seen)\n",
    "\n",
    "            cm = confusion_matrix(y_test.values.reshape(y_test.shape[0]), pred_values)\n",
    "            sensitivity = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "            specificity = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "            precision = (cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "\n",
    "            results_dict = {\n",
    "                \"accuracy\": accuracy_score(y_test, pred_values),\n",
    "                \"sensitivity\": sensitivity,\n",
    "                \"specificity\": specificity,\n",
    "                \"precision\": precision,\n",
    "                \"f1_score\": (2*precision*sensitivity)/(precision+sensitivity),\n",
    "                \"subject_acc\": subject_acc\n",
    "            }\n",
    "\n",
    "            fold_results.append(results_dict)\n",
    "        \n",
    "        current_results = {}\n",
    "        for i, result in enumerate(fold_results):\n",
    "            current_results[f\"split{i}_accuracy\"] = result[\"accuracy\"]\n",
    "            current_results[f\"split{i}_sensitivity\"] = result[\"sensitivity\"]\n",
    "            current_results[f\"split{i}_specificity\"] = result[\"specificity\"]\n",
    "            current_results[f\"split{i}_precision\"] = result[\"precision\"]\n",
    "            current_results[f\"split{i}_f1_score\"] = result[\"f1_score\"]\n",
    "            current_results[f\"split{i}_subject_acc\"] = result[\"subject_acc\"]\n",
    "        results[tuple(sorted(fit_params.items()))] = current_results\n",
    "        results[tuple(sorted(fit_params.items()))]['folds'] = len(splits)\n",
    "\n",
    "with open(f'saved_results_stepping_{current_weight}/svc_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0d73f7-0b7f-4602-8a74-691bed4a524e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "score_reporter(results, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec666c6c",
   "metadata": {
    "papermill": {
     "duration": 1591.980319,
     "end_time": "2023-02-25T02:46:48.217383",
     "exception": false,
     "start_time": "2023-02-25T02:20:16.237064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "folder = './joblib_memmap'\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "dump(X, os.path.join(folder, 'X'))\n",
    "X_memmap = load(os.path.join(folder, 'X'), mmap_mode='r')\n",
    "dump(y, os.path.join(folder, 'y'))\n",
    "y_memmap = load(os.path.join(folder, 'y'), mmap_mode='r')\n",
    "\n",
    "#num_combinations = 30\n",
    "params = {\n",
    "    \"n_estimators\": [1050],\n",
    "    \"max_depth\": [5]\n",
    "}\n",
    "param_grid = ParameterGrid(params)\n",
    "print(f'Fitting with {len(param_grid)} different parameter combinations')\n",
    "results = {}\n",
    "\n",
    "with tqdm(param_grid) as pbar:\n",
    "    for fit_params in pbar:\n",
    "        pbar.set_description(f'Fitting parameter combination: {fit_params}')\n",
    "        \n",
    "        clf = XGBClassifier(learning_rate = 0.1,\n",
    "                        verbose=None, \n",
    "                        eval_metric='logloss',\n",
    "                        tree_method='hist',\n",
    "                        **fit_params)\n",
    "        fold_results = Parallel(n_jobs=8)(\n",
    "            delayed(fit_xgboost_parallel)(clf, X_memmap, y_memmap, train, test, **fit_params)\n",
    "            for (train, test) in splits\n",
    "        )\n",
    "        \n",
    "        current_results = {}\n",
    "        for i, result in enumerate(fold_results):\n",
    "            current_results[f\"split{i}_accuracy\"] = result[\"accuracy\"]\n",
    "            current_results[f\"split{i}_sensitivity\"] = result[\"sensitivity\"]\n",
    "            current_results[f\"split{i}_specificity\"] = result[\"specificity\"]\n",
    "            current_results[f\"split{i}_precision\"] = result[\"precision\"]\n",
    "            current_results[f\"split{i}_f1_score\"] = result[\"f1_score\"]\n",
    "            current_results[f\"split{i}_feature_importances\"] = result[\"feature_importances\"]\n",
    "            current_results[f\"split{i}_subject_acc\"] = result[\"subject_acc\"]\n",
    "        results[tuple(sorted(fit_params.items()))] = current_results\n",
    "        results[tuple(sorted(fit_params.items()))]['folds'] = len(splits)\n",
    "\n",
    "with open(f'saved_results_stepping_{current_weight}/xg_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb321053",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "score_reporter(results, True, True, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1726e419",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CatBoost\n",
    "folder = './joblib_memmap'\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "dump(X, os.path.join(folder, 'X'))\n",
    "X_memmap = load(os.path.join(folder, 'X'), mmap_mode='r')\n",
    "dump(y, os.path.join(folder, 'y'))\n",
    "y_memmap = load(os.path.join(folder, 'y'), mmap_mode='r')\n",
    "\n",
    "#num_combinations = 15\n",
    "params = {\n",
    "    \"n_estimators\": [650],\n",
    "    \"max_depth\": [6]\n",
    "}\n",
    "param_grid = ParameterGrid(params)\n",
    "print(f'Fitting with {len(param_grid)} different parameter combinations')\n",
    "results = {}\n",
    "\n",
    "with tqdm(param_grid) as pbar:\n",
    "    for fit_params in pbar:\n",
    "        pbar.set_description(f'Fitting parameter combination: {fit_params}')\n",
    "        \n",
    "        clf = CatBoostClassifier(\n",
    "                        learning_rate=0.1,\n",
    "                        loss_function='Logloss',\n",
    "                        task_type=\"CPU\",\n",
    "                        silent=True,\n",
    "                        **fit_params)\n",
    "        fold_results = Parallel(n_jobs=1)(\n",
    "            delayed(fit_catboost_parallel)(clf, X_memmap, y_memmap, train, test, **fit_params)\n",
    "            for (train, test) in splits\n",
    "        )\n",
    "        \n",
    "        current_results = {}\n",
    "        for i, result in enumerate(fold_results):\n",
    "            current_results[f\"split{i}_accuracy\"] = result[\"accuracy\"]\n",
    "            current_results[f\"split{i}_sensitivity\"] = result[\"sensitivity\"]\n",
    "            current_results[f\"split{i}_specificity\"] = result[\"specificity\"]\n",
    "            current_results[f\"split{i}_precision\"] = result[\"precision\"]\n",
    "            current_results[f\"split{i}_f1_score\"] = result[\"f1_score\"]\n",
    "            current_results[f\"split{i}_feature_importances\"] = result[\"feature_importances\"]\n",
    "            current_results[f\"split{i}_subject_acc\"] = result[\"subject_acc\"]\n",
    "        results[tuple(sorted(fit_params.items()))] = current_results\n",
    "        results[tuple(sorted(fit_params.items()))]['folds'] = len(splits)\n",
    "\n",
    "with open(f'saved_results_stepping_{current_weight}/cb_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aa7c72",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "score_reporter(results, False, True, \"CatBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e57665d-40dd-4c73-a1da-060a9968fa73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LightGBM\n",
    "folder = './joblib_memmap'\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "dump(X, os.path.join(folder, 'X'))\n",
    "X_memmap = load(os.path.join(folder, 'X'), mmap_mode='r')\n",
    "dump(y, os.path.join(folder, 'y'))\n",
    "y_memmap = load(os.path.join(folder, 'y'), mmap_mode='r')\n",
    "\n",
    "#num_combinations = 15\n",
    "params = {\n",
    "    \"n_estimators\": [1000],\n",
    "    \"max_depth\": [5]\n",
    "}\n",
    "param_grid = ParameterGrid(params)\n",
    "print(f'Fitting with {len(param_grid)} different parameter combinations')\n",
    "results = {}\n",
    "\n",
    "with tqdm(param_grid) as pbar:\n",
    "    for fit_params in pbar:\n",
    "        pbar.set_description(f'Fitting parameter combination: {fit_params}')\n",
    "        \n",
    "        clf = lightgbm.LGBMClassifier(\n",
    "                        learning_rate=0.1,\n",
    "                        device=\"cpu\",\n",
    "                        verbose=-1,\n",
    "                        **fit_params)\n",
    "        fold_results = []\n",
    "        for (train, test) in tqdm(splits, leave=False):\n",
    "            X_train = X.iloc[train]\n",
    "            y_train = y.iloc[train]\n",
    "\n",
    "            X_test = X.iloc[test]\n",
    "            y_test = y.iloc[test]\n",
    "\n",
    "            cloned_clf = clone(clf)\n",
    "            cloned_clf.fit(X_train,y_train,eval_set=[(X_test,y_test),(X_train,y_train)], \n",
    "                   eval_metric='logloss')\n",
    "\n",
    "            pred_values = cloned_clf.predict(X_test)\n",
    "    \n",
    "            total_seen = 0\n",
    "            total_correct = 0\n",
    "            subject_acc = []\n",
    "            for idx, pred in enumerate(pred_values):\n",
    "                total_seen+=1\n",
    "                if pred==y_test.iloc[idx]:\n",
    "                    total_correct+=1\n",
    "                subject_acc.append(total_correct/total_seen)\n",
    "\n",
    "            cm = confusion_matrix(y_test.values.reshape(y_test.shape[0]), pred_values)\n",
    "            sensitivity = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "            specificity = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "            precision = (cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "\n",
    "            results_dict = {\n",
    "                \"accuracy\": accuracy_score(y_test, pred_values),\n",
    "                \"sensitivity\": sensitivity,\n",
    "                \"specificity\": specificity,\n",
    "                \"precision\": precision,\n",
    "                \"f1_score\": (2*precision*sensitivity)/(precision+sensitivity),\n",
    "                \"feature_importances\": {A: B for A, B in zip(cloned_clf.feature_name_, cloned_clf.feature_importances_)}, \n",
    "                \"subject_acc\": subject_acc\n",
    "            }\n",
    "\n",
    "            fold_results.append(results_dict)\n",
    "        \n",
    "        current_results = {}\n",
    "        for i, result in enumerate(fold_results):\n",
    "            current_results[f\"split{i}_accuracy\"] = result[\"accuracy\"]\n",
    "            current_results[f\"split{i}_sensitivity\"] = result[\"sensitivity\"]\n",
    "            current_results[f\"split{i}_specificity\"] = result[\"specificity\"]\n",
    "            current_results[f\"split{i}_precision\"] = result[\"precision\"]\n",
    "            current_results[f\"split{i}_f1_score\"] = result[\"f1_score\"]\n",
    "            current_results[f\"split{i}_feature_importances\"] = result[\"feature_importances\"]\n",
    "            current_results[f\"split{i}_subject_acc\"] = result[\"subject_acc\"]\n",
    "        results[tuple(sorted(fit_params.items()))] = current_results\n",
    "        results[tuple(sorted(fit_params.items()))]['folds'] = len(splits)\n",
    "\n",
    "with open(f'saved_results_stepping_{current_weight}/lg_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140bf673-8b2b-4398-bf95-6e68c4c3ac38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "score_reporter(results, False, True, \"LightGBM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab11c259-7735-4896-91fb-dd947510eae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:afib]",
   "language": "python",
   "name": "conda-env-afib-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1605.834912,
   "end_time": "2023-02-25T02:46:48.296192",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-25T02:20:02.461280",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "a54746d825bf8111bf1bc1a45ca74b0568535c84e3a9f74f4e5d3cbe6ec0015b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
