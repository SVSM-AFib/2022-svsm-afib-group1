{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01d441cb",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 3.698932,
     "end_time": "2023-02-25T02:20:14.724643",
     "exception": false,
     "start_time": "2023-02-25T02:20:11.025711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "from pathlib import Path, PurePath\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from joblib import Memory, Parallel, delayed\n",
    "from shutil import rmtree\n",
    "from collections import defaultdict\n",
    "\n",
    "import timeit\n",
    "\n",
    "import matplotlib_inline.backend_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\"retina\")\n",
    "\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import catboost as cb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49b7a70d",
   "metadata": {
    "papermill": {
     "duration": 0.024087,
     "end_time": "2023-02-25T02:20:14.753785",
     "exception": false,
     "start_time": "2023-02-25T02:20:14.729698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rlist = []\n",
    "records = PurePath(Path(os.getcwd()).parents[1], Path('mit-bih-dataframes/subject_list.csv'))\n",
    "with open(records) as rfile:\n",
    "    recordreader = csv.reader(rfile, delimiter=' ', quotechar='|')\n",
    "    for row in recordreader:\n",
    "        rlist.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc492292",
   "metadata": {
    "papermill": {
     "duration": 1.290393,
     "end_time": "2023-02-25T02:20:16.047768",
     "exception": false,
     "start_time": "2023-02-25T02:20:14.757375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2dd00c4544047e0812de087bd5b17e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_dfs = {}\n",
    "for record in tqdm(rlist):\n",
    "    feature_dfs[record] = pd.read_parquet(str(Path(os.getcwd()).parents[1]) + '/mit-bih-time-features/'+record+'.parquet')\n",
    "\n",
    "combined_features = pd.concat([feature_dfs[key][1:] for key in feature_dfs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be7bfc92",
   "metadata": {
    "papermill": {
     "duration": 0.105087,
     "end_time": "2023-02-25T02:20:16.157453",
     "exception": false,
     "start_time": "2023-02-25T02:20:16.052366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = combined_features[['StoS', 'StoR', 'StoL', 'RtoS', 'RtoR', 'RtoL', 'LtoS', 'LtoR', 'LtoL', 'std', 'cov', 'range', 'rrInt_var', 'rmean_var', 'rmssd', 'mad', 'iqr', 'drrmean', 'drrvar']]\n",
    "y = combined_features['mappedLabel'].map({\"Non-Afib\": 0, \"Afib\": 1})\n",
    "groups = combined_features['subjectID'].astype('int64')\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "splits = list(logo.split(X, y, groups=groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aa3ff85",
   "metadata": {
    "papermill": {
     "duration": 0.013836,
     "end_time": "2023-02-25T02:20:16.175323",
     "exception": false,
     "start_time": "2023-02-25T02:20:16.161487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.seterr(all='ignore')\n",
    "moving_accs = []\n",
    "\n",
    "if os.path.exists('saved_gridsearch')==False:\n",
    "    os.mkdir('saved_gridsearch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d54f2a18",
   "metadata": {
    "papermill": {
     "duration": 0.020048,
     "end_time": "2023-02-25T02:20:16.199212",
     "exception": false,
     "start_time": "2023-02-25T02:20:16.179164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def score_reporter(results):\n",
    "    bestParams = None\n",
    "    maxScore = 0\n",
    "    for params, scores in results.items():\n",
    "        num_splits = scores['folds']\n",
    "        accuracy = [scores[f\"split{i}_accuracy\"] for i in range(num_splits)]\n",
    "        print(params, np.mean(accuracy))\n",
    "        \n",
    "        if (np.mean(accuracy) > maxScore):\n",
    "            bestParams = params\n",
    "            maxScore = np.mean(accuracy)\n",
    "            \n",
    "    bestScores = results[bestParams]\n",
    "    num_splits = bestScores['folds']\n",
    "    accuracy = [bestScores[f\"split{i}_accuracy\"] for i in range(num_splits)]\n",
    "    sensitivity = [bestScores[f\"split{i}_sensitivity\"] for i in range(num_splits)]\n",
    "    specificity = [bestScores[f\"split{i}_specificity\"] for i in range(num_splits)]\n",
    "    precision = [bestScores[f\"split{i}_precision\"] for i in range(num_splits)]\n",
    "    f1_score = [bestScores[f\"split{i}_f1_score\"] for i in range(num_splits)]\n",
    "    \n",
    "    n_features_selected = [bestScores[f\"split{i}_n_features\"] for i in range(num_splits)]\n",
    "    feature_rankings = [bestScores[f\"split{i}_ranking\"] for i in range(num_splits)]\n",
    "    \n",
    "    avg_rankings = np.mean(np.array(feature_rankings), axis=0)\n",
    "    feature_names = bestScores[\"split0_feature_names_in\"][0]\n",
    "    mapped_rankings = {name: rank for name, rank in zip(feature_names, avg_rankings.flatten())}\n",
    "    \n",
    "    print(f\"The best parameters were {bestParams}\")\n",
    "    print(f\"Accuracy for each fold: {accuracy}\")\n",
    "    print(f\"Mean accuracy: {np.mean(accuracy)}\")\n",
    "    print(f\"Std accuracy: {np.std(accuracy)}\")\n",
    "    print(f\"Sensitivity for each fold: {sensitivity}\")\n",
    "    print(f\"Mean sensitivity: {np.mean(sensitivity)}\")\n",
    "    print(f\"Std sensitivity: {np.std(sensitivity)}\")\n",
    "    print(f\"Specificity for each fold: {specificity}\")\n",
    "    print(f\"Mean specificity: {np.mean(specificity)}\")\n",
    "    print(f\"Std specificity: {np.std(specificity)}\")\n",
    "    print(f\"Precision for each fold: {precision}\")\n",
    "    print(f\"Mean precision: {np.mean(precision)}\")\n",
    "    print(f\"Std precision: {np.std(precision)}\")\n",
    "    print(f\"F1-score for each fold: {f1_score}\")\n",
    "    print(f\"Mean F1-score: {np.mean(f1_score)}\")\n",
    "    print(f\"Std F1-score: {np.std(f1_score)}\")\n",
    "    print(f\"Number of features selected in each fold: {n_features_selected}\")\n",
    "    print(f\"Mean number of features selected: {np.mean(n_features_selected)}\")\n",
    "    print(\"Average feature ranking: \")\n",
    "    print(mapped_rankings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb1b77e9",
   "metadata": {
    "papermill": {
     "duration": 0.012606,
     "end_time": "2023-02-25T02:20:16.215884",
     "exception": false,
     "start_time": "2023-02-25T02:20:16.203278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit_transform_cacheable(transformer, X, y, **fit_params):\n",
    "    if hasattr(transformer, \"fit_transform\"):\n",
    "        res = transformer.fit_transform(X, y, **fit_params)\n",
    "    else:\n",
    "        res = transformer.fit(X, y, **fit_params).transform(X)\n",
    "\n",
    "    return res, transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a46d4028",
   "metadata": {
    "papermill": {
     "duration": 0.012847,
     "end_time": "2023-02-25T02:20:16.232934",
     "exception": false,
     "start_time": "2023-02-25T02:20:16.220087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "location = \"cache\"\n",
    "#rmtree(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec666c6c",
   "metadata": {
    "papermill": {
     "duration": 1591.980319,
     "end_time": "2023-02-25T02:46:48.217383",
     "exception": false,
     "start_time": "2023-02-25T02:20:16.237064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with 162 different parameter combinations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c69b569309774bdcae36b93f3e2f57e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# XGBoost\n",
    "memory = Memory(location=location, verbose=0)\n",
    "fit_transform_cached = memory.cache(fit_transform_cacheable)\n",
    "\n",
    "feature_selection_clf = XGBClassifier(n_estimators=150,\n",
    "                          max_depth=4,\n",
    "                          eval_metric='logloss', \n",
    "                          learning_rate=0.1, \n",
    "                          tree_method=\"gpu_hist\",\n",
    "                          verbosity=0)\n",
    "\n",
    "def fit_xgboost_parallel(X, y, train, test, feature_selection_clf, **fit_params):\n",
    "    np.seterr(all='ignore')\n",
    "    \n",
    "    X_train = X.iloc[train]\n",
    "    y_train = y.iloc[train]\n",
    "\n",
    "    X_test = X.iloc[test]\n",
    "    y_test = y.iloc[test]\n",
    "\n",
    "    #rfe_start_time = timeit.default_timer()\n",
    "    train_groups = groups.iloc[train]\n",
    "    rfecv_splits = list(LeaveOneGroupOut().split(X_train, y_train, groups=train_groups))\n",
    "    rfecv = RFECV(estimator=clone(feature_selection_clf), \n",
    "                  cv=rfecv_splits,\n",
    "                  step=2,\n",
    "                  scoring=\"accuracy\",\n",
    "                  n_jobs=1)\n",
    "\n",
    "    #print('RFECV fitting started')\n",
    "    X_train, rfecv = fit_transform_cached(rfecv, X_train, y_train)\n",
    "    #print(f'RFECV fitting took {timeit.default_timer()-rfe_start_time} seconds')\n",
    "    #print(f'{rfecv.n_features_} features selected')\n",
    "\n",
    "    #clf_start_time = timeit.default_timer()\n",
    "    clf = XGBClassifier(learning_rate = 0.1,\n",
    "                        verbose=None, \n",
    "                        eval_metric='logloss',\n",
    "                        tree_method='gpu_hist',\n",
    "                        **fit_params)\n",
    "    #print('classifier fitting started')\n",
    "    clf.fit(X_train, y_train)\n",
    "    #print(f'classifier fitting took {timeit.default_timer()-clf_start_time} seconds')\n",
    "\n",
    "    pred_values = clf.predict(rfecv.transform(X_test))\n",
    "\n",
    "    cm = confusion_matrix(y_test.values.reshape(y_test.shape[0]), pred_values)\n",
    "    sensitivity = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "    specificity = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "    precision = (cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "\n",
    "    results_dict = {\n",
    "        \"accuracy\": accuracy_score(y_test, pred_values),\n",
    "        \"sensitivity\": sensitivity,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision,\n",
    "        \"f1_score\": (2*precision*sensitivity)/(precision+sensitivity),\n",
    "        \"n_features\": rfecv.n_features_,\n",
    "        \"ranking\": rfecv.ranking_,\n",
    "        \"feature_names_in\": rfecv.feature_names_in_,\n",
    "        \"feature_importances\": clf.feature_importances_\n",
    "    }\n",
    "    \n",
    "    return results_dict\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": np.arange(100, 1000, 50),\n",
    "    \"max_depth\": np.arange(2, 11)\n",
    "}\n",
    "param_grid = ParameterGrid(params)\n",
    "print(f'Fitting with {len(param_grid)} different parameter combinations')\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "results = {}\n",
    "\n",
    "with tqdm(param_grid) as pbar:\n",
    "    for fit_params in pbar:\n",
    "        current_results = defaultdict(list)\n",
    "\n",
    "        pbar.set_description(f'Fitting parameter combination: {fit_params}')\n",
    "        fold_results = Parallel(n_jobs=8, max_nbytes=1e6)(\n",
    "            delayed(fit_xgboost_parallel)(X, y, train, test, feature_selection_clf, **fit_params)\n",
    "            for (train, test) in splits\n",
    "        )\n",
    "        \n",
    "        for i, result in enumerate(fold_results):\n",
    "            current_results[f\"split{i}_accuracy\"].append(result[\"accuracy\"])\n",
    "            current_results[f\"split{i}_sensitivity\"].append(result[\"sensitivity\"])\n",
    "            current_results[f\"split{i}_specificity\"].append(result[\"specificity\"])\n",
    "            current_results[f\"split{i}_precision\"].append(result[\"precision\"])\n",
    "            current_results[f\"split{i}_f1_score\"].append(result[\"f1_score\"])\n",
    "            current_results[f\"split{i}_n_features\"].append(result[\"n_features\"])\n",
    "            current_results[f\"split{i}_ranking\"].append(result[\"ranking\"])\n",
    "            current_results[f\"split{i}_feature_names_in\"].append(result[\"feature_names_in\"])\n",
    "            current_results[f\"split{i}_feature_importances\"].append(result[\"feature_importances\"])\n",
    "        results[tuple(sorted(fit_params.items()))] = current_results\n",
    "        results[tuple(sorted(fit_params.items()))]['folds'] = len(splits)\n",
    "\n",
    "with open('saved_gridsearch/xg_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Delete the temporary cache before exiting\n",
    "# memory.clear(warn=False)\n",
    "# rmtree(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb321053",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('max_depth', 2), ('n_estimators', 100)) 0.9280052424651943\n",
      "(('max_depth', 2), ('n_estimators', 150)) 0.929648653804492\n",
      "(('max_depth', 2), ('n_estimators', 200)) 0.9288538957476153\n",
      "(('max_depth', 2), ('n_estimators', 250)) 0.9312140488056105\n",
      "(('max_depth', 2), ('n_estimators', 300)) 0.9323368059767886\n",
      "(('max_depth', 2), ('n_estimators', 350)) 0.9339229946391171\n",
      "(('max_depth', 2), ('n_estimators', 400)) 0.9346330812404043\n",
      "(('max_depth', 2), ('n_estimators', 450)) 0.9350308155131625\n",
      "(('max_depth', 2), ('n_estimators', 500)) 0.9347088120475971\n",
      "(('max_depth', 2), ('n_estimators', 550)) 0.9361975191585422\n",
      "(('max_depth', 2), ('n_estimators', 600)) 0.9348457657852421\n",
      "(('max_depth', 2), ('n_estimators', 650)) 0.935576942238135\n",
      "(('max_depth', 2), ('n_estimators', 700)) 0.9355685567017306\n",
      "(('max_depth', 2), ('n_estimators', 750)) 0.9355800313093569\n",
      "(('max_depth', 2), ('n_estimators', 800)) 0.9355916172904685\n",
      "(('max_depth', 2), ('n_estimators', 850)) 0.9356369215148763\n",
      "(('max_depth', 2), ('n_estimators', 900)) 0.9349508162396584\n",
      "(('max_depth', 2), ('n_estimators', 950)) 0.9350474208946823\n",
      "(('max_depth', 3), ('n_estimators', 100)) 0.9273449119897607\n",
      "(('max_depth', 3), ('n_estimators', 150)) 0.9284412961121131\n",
      "(('max_depth', 3), ('n_estimators', 200)) 0.9289760987037561\n",
      "(('max_depth', 3), ('n_estimators', 250)) 0.9287555228001125\n",
      "(('max_depth', 3), ('n_estimators', 300)) 0.9281522604886585\n",
      "(('max_depth', 3), ('n_estimators', 350)) 0.9271677016274005\n",
      "(('max_depth', 3), ('n_estimators', 400)) 0.9273033083477217\n",
      "(('max_depth', 3), ('n_estimators', 450)) 0.9282487191318367\n",
      "(('max_depth', 3), ('n_estimators', 500)) 0.9278476128857635\n",
      "(('max_depth', 3), ('n_estimators', 550)) 0.9277218008852668\n",
      "(('max_depth', 3), ('n_estimators', 600)) 0.9276561525601236\n",
      "(('max_depth', 3), ('n_estimators', 650)) 0.9266527618876657\n",
      "(('max_depth', 3), ('n_estimators', 700)) 0.926239717361888\n",
      "(('max_depth', 3), ('n_estimators', 750)) 0.9250635665929496\n",
      "(('max_depth', 3), ('n_estimators', 800)) 0.9247136464199216\n",
      "(('max_depth', 3), ('n_estimators', 850)) 0.9239983958702425\n",
      "(('max_depth', 3), ('n_estimators', 900)) 0.9239980538136865\n",
      "(('max_depth', 3), ('n_estimators', 950)) 0.922406510984916\n",
      "(('max_depth', 4), ('n_estimators', 100)) 0.9251473930637235\n",
      "(('max_depth', 4), ('n_estimators', 150)) 0.9263554974208558\n",
      "(('max_depth', 4), ('n_estimators', 200)) 0.9266385115883368\n",
      "(('max_depth', 4), ('n_estimators', 250)) 0.9268334195567486\n",
      "(('max_depth', 4), ('n_estimators', 300)) 0.9253718904451348\n",
      "(('max_depth', 4), ('n_estimators', 350)) 0.9250434432829742\n",
      "(('max_depth', 4), ('n_estimators', 400)) 0.9243100755219184\n",
      "(('max_depth', 4), ('n_estimators', 450)) 0.9242725245475264\n",
      "(('max_depth', 4), ('n_estimators', 500)) 0.9232792361040929\n",
      "(('max_depth', 4), ('n_estimators', 550)) 0.9224005954563634\n",
      "(('max_depth', 4), ('n_estimators', 600)) 0.9216106471135845\n",
      "(('max_depth', 4), ('n_estimators', 650)) 0.9213407858110997\n",
      "(('max_depth', 4), ('n_estimators', 700)) 0.9203168311567357\n",
      "(('max_depth', 4), ('n_estimators', 750)) 0.9198359146674029\n",
      "(('max_depth', 4), ('n_estimators', 800)) 0.9190710940671896\n",
      "(('max_depth', 4), ('n_estimators', 850)) 0.9187400214789924\n",
      "(('max_depth', 4), ('n_estimators', 900)) 0.9178519359156381\n",
      "(('max_depth', 4), ('n_estimators', 950)) 0.9173259107981129\n",
      "(('max_depth', 5), ('n_estimators', 100)) 0.9206991235213313\n",
      "(('max_depth', 5), ('n_estimators', 150)) 0.9168670580229362\n",
      "(('max_depth', 5), ('n_estimators', 200)) 0.9157580886734967\n",
      "(('max_depth', 5), ('n_estimators', 250)) 0.9146497591189451\n",
      "(('max_depth', 5), ('n_estimators', 300)) 0.9136052118621744\n",
      "(('max_depth', 5), ('n_estimators', 350)) 0.9138783133256262\n",
      "(('max_depth', 5), ('n_estimators', 400)) 0.913367814397377\n",
      "(('max_depth', 5), ('n_estimators', 450)) 0.9130854949209568\n",
      "(('max_depth', 5), ('n_estimators', 500)) 0.9133442690477552\n",
      "(('max_depth', 5), ('n_estimators', 550)) 0.9130394760379038\n",
      "(('max_depth', 5), ('n_estimators', 600)) 0.9126129514876528\n",
      "(('max_depth', 5), ('n_estimators', 650)) 0.9130514000485206\n",
      "(('max_depth', 5), ('n_estimators', 700)) 0.9140040942529296\n",
      "(('max_depth', 5), ('n_estimators', 750)) 0.913820551502235\n",
      "(('max_depth', 5), ('n_estimators', 800)) 0.913879963645166\n",
      "(('max_depth', 5), ('n_estimators', 850)) 0.9149350800734449\n",
      "(('max_depth', 5), ('n_estimators', 900)) 0.9153630508609246\n",
      "(('max_depth', 5), ('n_estimators', 950)) 0.9150001229751122\n",
      "(('max_depth', 6), ('n_estimators', 100)) 0.9123947863673192\n",
      "(('max_depth', 6), ('n_estimators', 150)) 0.9102727537150033\n",
      "(('max_depth', 6), ('n_estimators', 200)) 0.9110972613268705\n",
      "(('max_depth', 6), ('n_estimators', 250)) 0.9112060409525036\n",
      "(('max_depth', 6), ('n_estimators', 300)) 0.9111910912660569\n",
      "(('max_depth', 6), ('n_estimators', 350)) 0.9112761460255199\n",
      "(('max_depth', 6), ('n_estimators', 400)) 0.9121713919583554\n",
      "(('max_depth', 6), ('n_estimators', 450)) 0.912044749277197\n",
      "(('max_depth', 6), ('n_estimators', 500)) 0.9136725243257423\n",
      "(('max_depth', 6), ('n_estimators', 550)) 0.9144867852136715\n",
      "(('max_depth', 6), ('n_estimators', 600)) 0.9147466534502184\n",
      "(('max_depth', 6), ('n_estimators', 650)) 0.914769379247531\n",
      "(('max_depth', 6), ('n_estimators', 700)) 0.9154232473972791\n",
      "(('max_depth', 6), ('n_estimators', 750)) 0.9157265517133111\n",
      "(('max_depth', 6), ('n_estimators', 800)) 0.9156721971695362\n",
      "(('max_depth', 6), ('n_estimators', 850)) 0.9163299421357196\n",
      "(('max_depth', 6), ('n_estimators', 900)) 0.9167324465517138\n",
      "(('max_depth', 6), ('n_estimators', 950)) 0.9171115613520859\n",
      "(('max_depth', 7), ('n_estimators', 100)) 0.9098859461777645\n",
      "(('max_depth', 7), ('n_estimators', 150)) 0.9083961429608387\n",
      "(('max_depth', 7), ('n_estimators', 200)) 0.9091029489082983\n",
      "(('max_depth', 7), ('n_estimators', 250)) 0.9099082013992351\n",
      "(('max_depth', 7), ('n_estimators', 300)) 0.9117458769192929\n",
      "(('max_depth', 7), ('n_estimators', 350)) 0.9130652419886358\n",
      "(('max_depth', 7), ('n_estimators', 400)) 0.9132090484016494\n",
      "(('max_depth', 7), ('n_estimators', 450)) 0.9131870721307057\n",
      "(('max_depth', 7), ('n_estimators', 500)) 0.9136918275920674\n",
      "(('max_depth', 7), ('n_estimators', 550)) 0.9143005515089659\n",
      "(('max_depth', 7), ('n_estimators', 600)) 0.9148874344877147\n",
      "(('max_depth', 7), ('n_estimators', 650)) 0.9147828460684787\n",
      "(('max_depth', 7), ('n_estimators', 700)) 0.9147836343782616\n",
      "(('max_depth', 7), ('n_estimators', 750)) 0.9148849768292584\n",
      "(('max_depth', 7), ('n_estimators', 800)) 0.9153008164654347\n",
      "(('max_depth', 7), ('n_estimators', 850)) 0.9155338028339858\n",
      "(('max_depth', 7), ('n_estimators', 900)) 0.9158730496387454\n",
      "(('max_depth', 7), ('n_estimators', 950)) 0.9161463382717685\n",
      "(('max_depth', 8), ('n_estimators', 100)) 0.913567451226087\n",
      "(('max_depth', 8), ('n_estimators', 150)) 0.9121521250660648\n",
      "(('max_depth', 8), ('n_estimators', 200)) 0.9130478174247546\n",
      "(('max_depth', 8), ('n_estimators', 250)) 0.9142515076261577\n",
      "(('max_depth', 8), ('n_estimators', 300)) 0.9151841344888235\n",
      "(('max_depth', 8), ('n_estimators', 350)) 0.9158379935807226\n",
      "(('max_depth', 8), ('n_estimators', 400)) 0.9163938420738683\n",
      "(('max_depth', 8), ('n_estimators', 450)) 0.9165444303210719\n",
      "(('max_depth', 8), ('n_estimators', 500)) 0.9170319977064733\n",
      "(('max_depth', 8), ('n_estimators', 550)) 0.9173865013962466\n",
      "(('max_depth', 8), ('n_estimators', 600)) 0.9174160520693826\n",
      "(('max_depth', 8), ('n_estimators', 650)) 0.917865794458282\n",
      "(('max_depth', 8), ('n_estimators', 700)) 0.9183452480398308\n",
      "(('max_depth', 8), ('n_estimators', 750)) 0.9185450024163798\n",
      "(('max_depth', 8), ('n_estimators', 800)) 0.9187145071846434\n",
      "(('max_depth', 8), ('n_estimators', 850)) 0.9190343855317515\n",
      "(('max_depth', 8), ('n_estimators', 900)) 0.9193292433891959\n",
      "(('max_depth', 8), ('n_estimators', 950)) 0.9194987409375585\n",
      "(('max_depth', 9), ('n_estimators', 100)) 0.9110343209896582\n",
      "(('max_depth', 9), ('n_estimators', 150)) 0.9114807498767794\n",
      "(('max_depth', 9), ('n_estimators', 200)) 0.9132971940428457\n",
      "(('max_depth', 9), ('n_estimators', 250)) 0.9149284166212349\n",
      "(('max_depth', 9), ('n_estimators', 300)) 0.9155352868316021\n",
      "(('max_depth', 9), ('n_estimators', 350)) 0.9159724164548984\n",
      "(('max_depth', 9), ('n_estimators', 400)) 0.9165158078134463\n",
      "(('max_depth', 9), ('n_estimators', 450)) 0.9172645979571729\n",
      "(('max_depth', 9), ('n_estimators', 500)) 0.9175893941535327\n",
      "(('max_depth', 9), ('n_estimators', 550)) 0.9178321567132622\n",
      "(('max_depth', 9), ('n_estimators', 600)) 0.9183836757543327\n",
      "(('max_depth', 9), ('n_estimators', 650)) 0.9188256781424069\n",
      "(('max_depth', 9), ('n_estimators', 700)) 0.9188689288441717\n",
      "(('max_depth', 9), ('n_estimators', 750)) 0.9189479443796552\n",
      "(('max_depth', 9), ('n_estimators', 800)) 0.9193922228259619\n",
      "(('max_depth', 9), ('n_estimators', 850)) 0.9197930637404556\n",
      "(('max_depth', 9), ('n_estimators', 900)) 0.9201213876613477\n",
      "(('max_depth', 9), ('n_estimators', 950)) 0.9202925531644399\n",
      "(('max_depth', 10), ('n_estimators', 100)) 0.9112850752138348\n",
      "(('max_depth', 10), ('n_estimators', 150)) 0.9118057466061389\n",
      "(('max_depth', 10), ('n_estimators', 200)) 0.9137217654216919\n",
      "(('max_depth', 10), ('n_estimators', 250)) 0.914571743726622\n",
      "(('max_depth', 10), ('n_estimators', 300)) 0.915490932326618\n",
      "(('max_depth', 10), ('n_estimators', 350)) 0.9165402458083195\n",
      "(('max_depth', 10), ('n_estimators', 400)) 0.9173714654679882\n",
      "(('max_depth', 10), ('n_estimators', 450)) 0.9182351269491896\n",
      "(('max_depth', 10), ('n_estimators', 500)) 0.9186068793799068\n",
      "(('max_depth', 10), ('n_estimators', 550)) 0.9190492666888328\n",
      "(('max_depth', 10), ('n_estimators', 600)) 0.9193429643027007\n",
      "(('max_depth', 10), ('n_estimators', 650)) 0.9195845801490742\n",
      "(('max_depth', 10), ('n_estimators', 700)) 0.9195177975991321\n",
      "(('max_depth', 10), ('n_estimators', 750)) 0.9200413552365624\n",
      "(('max_depth', 10), ('n_estimators', 800)) 0.9199705049799592\n",
      "(('max_depth', 10), ('n_estimators', 850)) 0.9202004171958648\n",
      "(('max_depth', 10), ('n_estimators', 900)) 0.9202047353224054\n",
      "(('max_depth', 10), ('n_estimators', 950)) 0.9202969640684714\n",
      "The best parameters were (('max_depth', 2), ('n_estimators', 550))\n",
      "Accuracy for each fold: [[0.9607655502392345], [0.9291330938743811], [0.9879336349924586], [0.7123806850084222], [0.9978645898756437], [0.914647201946472], [0.8965478592243892], [0.9880504174169259], [0.929957805907173], [0.9772757299511164], [0.9705593719332679], [0.9903231380680836], [0.889760348583878], [0.9765553171927674], [0.858354114713217], [0.9886897140418267], [0.9705346796887933], [0.9665510062456627], [0.7041168120056783], [0.9574524312896406], [0.9984679807986927], [0.96843853820598], [0.9981829194427619]]\n",
      "Mean accuracy: 0.9361975191585422\n",
      "Std accuracy: 0.07955361975982134\n",
      "Sensitivity for each fold: [[0.9615331396153314], [0.9628120224146715], [0.988760585065435], [0.6888010940586538], [0.998223169864961], [0.9062869425040301], [0.9287266405910474], [0.9888268156424581], [0.9511828764551258], [0.9827260458839406], [0.20783132530120482], [0.9964992123227726], [0.8099783080260303], [nan], [nan], [0.9671101256467111], [0.9652014652014652], [0.989330171902786], [0.6121195942338494], [0.9893899204244032], [1.0], [1.0], [0.9952569169960475]]\n",
      "Mean sensitivity: nan\n",
      "Std sensitivity: nan\n",
      "Specificity for each fold: [[0.8977272727272727], [0.8211514904042466], [0.9481481481481482], [0.998158379373849], [0.997668544783369], [0.9948453608247423], [0.8853647485274128], [0.782608695652174], [0.919921875], [0.7232704402515723], [0.9992080552098653], [0.5135135135135135], [0.9702407002188184], [0.9765553171927674], [0.858354114713217], [0.9974497449744975], [0.9937888198757764], [0.959586806814063], [0.9949367088607595], [0.8630423418714062], [0.9980042575838212], [0.45714285714285713], [0.9991865509761388]]\n",
      "Mean specificity: 0.8934728149843604\n",
      "Std specificity: 0.14757252658853495\n",
      "Precision for each fold: [[0.9987065248634666], [0.9452363090772693], [0.9989111836988646], [0.9997794441993825], [0.9957461892945764], [0.9994074425219246], [0.737914364640884], [0.999169848912502], [0.8488605898123325], [0.993993993993994], [0.9078947368421053], [0.9937161808343515], [0.9648578811369509], [0.0], [0.0], [0.9935459377372817], [0.9985263157894737], [0.8821353065539113], [0.9973901696389734], [0.9552672016390644], [0.9934497816593887], [0.9675767918088737], [0.9976228209191759]]\n",
      "Mean precision: 0.8769438702423803\n",
      "Std precision: 0.27765367273238123\n",
      "F1-score for each fold: [[0.9797673598872049], [0.9539432176656151], [0.9938099659548129], [0.8156545209176788], [0.9969831410825201], [0.9505720565856958], [0.8223975370406004], [0.9939714262119085], [0.8971135115990791], [0.9883279044516831], [0.33823529411764713], [0.995105750742877], [0.8806603773584906], [nan], [nan], [0.9801498127340824], [0.9815811258278145], [0.932662754959486], [0.7586435070306038], [0.9720291869353719], [0.9967141292442497], [0.9835212489158716], [0.9964384645825088]]\n",
      "Mean F1-score: nan\n",
      "Std F1-score: nan\n",
      "Number of features selected in each fold: [[17], [15], [19], [17], [19], [17], [15], [15], [13], [19], [17], [15], [19], [17], [19], [15], [19], [19], [17], [19], [19], [17], [17]]\n",
      "Mean number of features selected: 17.17391304347826\n",
      "Average feature ranking: \n",
      "{'StoS': 1.0, 'StoR': 1.0, 'StoL': 1.0, 'RtoS': 1.7826086956521738, 'RtoR': 1.3043478260869565, 'RtoL': 1.0, 'LtoS': 1.0, 'LtoR': 1.0, 'LtoL': 1.0434782608695652, 'std': 1.3043478260869565, 'cov': 1.0, 'range': 1.0, 'rrInt_var': 1.0, 'rmean_var': 1.565217391304348, 'rmssd': 1.5217391304347827, 'mad': 1.0, 'iqr': 1.0, 'drrmean': 1.0, 'drrvar': 1.0}\n"
     ]
    }
   ],
   "source": [
    "score_reporter(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1726e419",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-02-24T01:18:14.970930Z",
     "iopub.status.busy": "2023-02-24T01:18:14.970557Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CatBoost\n",
    "feature_selection_clf = XGBClassifier(n_estimators=75, \n",
    "                                      max_depth=3, \n",
    "                                      eval_metric='logloss', \n",
    "                                      learning_rate=0.1, \n",
    "                                      tree_method=\"gpu_hist\",\n",
    "                                      verbosity=2)\n",
    "\n",
    "memory = Memory(location=location, verbose=10)\n",
    "fit_transform_cached = memory.cache(fit_transform_cacheable)\n",
    "\n",
    "params = {\n",
    "    \"iterations\": np.arange(350, 550, 25),\n",
    "    \"depth\": np.arange(3, 7)\n",
    "}\n",
    "param_grid = ParameterGrid(params)\n",
    "print(f'Fitting with {len(param_grid)} different parameter combinations')\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "results = {}\n",
    "for fit_params in param_grid:\n",
    "    current_results = defaultdict(list)\n",
    "    \n",
    "    print(f'Fitting parameter combination: {fit_params}')\n",
    "    Truth = []\n",
    "    Output = []\n",
    "\n",
    "    for i, (train, test) in enumerate(splits):\n",
    "        X_train = X.iloc[train]\n",
    "        y_train = y.iloc[train]\n",
    "\n",
    "        X_test = X.iloc[test]\n",
    "        y_test = y.iloc[test]\n",
    "\n",
    "        rfe_start_time = timeit.default_timer()\n",
    "        train_groups = groups.iloc[train]\n",
    "        rfecv_splits = list(logo.split(X_train, y_train, groups=train_groups))\n",
    "        rfecv = RFECV(estimator=feature_selection_clf, \n",
    "                      cv=rfecv_splits,\n",
    "                      n_jobs=-1)\n",
    "        \n",
    "        X_train, rfecv = fit_transform_cached(rfecv, X_train, y_train)\n",
    "        print(f'RFECV fitting took {timeit.default_timer()-rfe_start_time} seconds')\n",
    "        print(f'{X_train.shape} shape of selected X_train')\n",
    "\n",
    "        clf_start_time = timeit.default_timer()\n",
    "        clf = CatBoostClassifier(\n",
    "                        learning_rate=0.1,\n",
    "                        loss_function='Logloss',\n",
    "                        task_type=\"GPU\",\n",
    "                        silent=True,\n",
    "                        **fit_params)\n",
    "        print('classifier created, fitting now')\n",
    "        clf.fit(X_train, y_train)\n",
    "        print(f'classifier fitting took {timeit.default_timer()-clf_start_time} seconds')\n",
    "\n",
    "        pred_values = clf.predict(rfecv.transform(X_test))\n",
    "\n",
    "        cm = confusion_matrix(y_test.values.reshape(y_test.shape[0]), pred_values)\n",
    "        sensitivity = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "        specificity = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "        precision = (cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "        f1_score = (2*precision*sensitivity)/(precision+sensitivity)\n",
    "        acc = accuracy_score(y_test, pred_values)\n",
    "\n",
    "        current_results[f\"split{i}_accuracy\"].append(acc)\n",
    "        current_results[f\"split{i}_sensitivity\"].append(sensitivity)\n",
    "        current_results[f\"split{i}_specificity\"].append(specificity)\n",
    "        current_results[f\"split{i}_precision\"].append(precision)\n",
    "        current_results[f\"split{i}_f1_score\"].append(f1_score)\n",
    "\n",
    "        print(f\"split {i} complete - accuracy={acc}, sensitivity={sensitivity}, specificity={specificity}, precision={precision}, f1_score={f1_score}\")\n",
    "\n",
    "        current_results[f\"split{i}_rfecv\"].append(rfecv)\n",
    "        current_results[f\"split{i}_clf\"].append(clf)\n",
    "    results[tuple(sorted(fit_params.items()))] = current_results\n",
    "    results[tuple(sorted(fit_params.items()))]['folds'] = len(splits)\n",
    "\n",
    "with open('saved_gridsearch/cb_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(results)\n",
    "\n",
    "# Delete the temporary cache before exiting\n",
    "memory.clear(warn=False)\n",
    "rmtree(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aa7c72",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "score_reporter(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:afib]",
   "language": "python",
   "name": "conda-env-afib-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1605.834912,
   "end_time": "2023-02-25T02:46:48.296192",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-25T02:20:02.461280",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "a54746d825bf8111bf1bc1a45ca74b0568535c84e3a9f74f4e5d3cbe6ec0015b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
