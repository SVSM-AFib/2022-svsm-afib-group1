{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01d441cb",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 3.698932,
     "end_time": "2023-02-25T02:20:14.724643",
     "exception": false,
     "start_time": "2023-02-25T02:20:11.025711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "from pathlib import Path, PurePath\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pickle\n",
    "from joblib import Parallel, delayed, dump, load\n",
    "from shutil import rmtree\n",
    "from collections import defaultdict\n",
    "\n",
    "import timeit\n",
    "\n",
    "import matplotlib_inline.backend_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\"retina\")\n",
    "\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from cuml.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from cuml.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import catboost as cb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49b7a70d",
   "metadata": {
    "papermill": {
     "duration": 0.024087,
     "end_time": "2023-02-25T02:20:14.753785",
     "exception": false,
     "start_time": "2023-02-25T02:20:14.729698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rlist = []\n",
    "records = PurePath(Path(os.getcwd()).parents[1], Path('mit-bih-dataframes/subject_list.csv'))\n",
    "with open(records) as rfile:\n",
    "    recordreader = csv.reader(rfile, delimiter=' ', quotechar='|')\n",
    "    for row in recordreader:\n",
    "        rlist.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c823dc1-1c09-4f6b-ac21-367cc8a9e904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_rr_ints(df):\n",
    "    #list of types of rr_ints for each subject\n",
    "    subject_types = []\n",
    "    for row in df.itertuples():\n",
    "        if row.rrInt < 0.85*row.rmean: \n",
    "            #if rr_ints is less than 85% of runningmean\n",
    "            #label subject type as short\n",
    "            subject_types.append('short')\n",
    "        elif row.rrInt > 1.15*row.rmean: \n",
    "            #if rr_ints is greater than 115% of runningmean\n",
    "            #label subject type as long\n",
    "            subject_types.append('long')\n",
    "        else:\n",
    "            #label subject type as regular\n",
    "            subject_types.append('regular')\n",
    "    \n",
    "    return subject_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05eff50b-1242-494d-b1e4-2e4f24be5064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_proportions(int_types):\n",
    "    StoS = 0\n",
    "    StoR = 0\n",
    "    StoL = 0\n",
    "    RtoS = 0\n",
    "    RtoR = 0\n",
    "    RtoL = 0\n",
    "    LtoS = 0\n",
    "    LtoR = 0\n",
    "    LtoL = 0\n",
    "    for idx in range(len(int_types)):\n",
    "        if idx<len(int_types)-1:\n",
    "            if int_types[idx]=='short' and int_types[idx+1]=='short':\n",
    "                StoS+=1\n",
    "            elif int_types[idx]=='short' and int_types[idx+1]=='regular':\n",
    "                StoR+=1\n",
    "            elif int_types[idx]=='short' and int_types[idx+1]=='long':\n",
    "                StoL+=1\n",
    "            elif int_types[idx]=='regular' and int_types[idx+1]=='short':\n",
    "                RtoS+=1\n",
    "            elif int_types[idx]=='regular' and int_types[idx+1]=='regular':\n",
    "                RtoR+=1\n",
    "            elif int_types[idx]=='regular' and int_types[idx+1]=='long':\n",
    "                RtoL+=1\n",
    "            elif int_types[idx]=='long' and int_types[idx+1]=='short':\n",
    "                LtoS+=1\n",
    "            elif int_types[idx]=='long' and int_types[idx+1]=='regular':\n",
    "                LtoR+=1\n",
    "            elif int_types[idx]=='long' and int_types[idx+1]=='long':\n",
    "                LtoL+=1\n",
    "    \n",
    "    count = len(int_types)-1\n",
    "    subject_transitions = [StoS/count, StoR/count, StoL/count, RtoS/count, RtoR/count, RtoL/count, LtoS/count, LtoR/count, LtoL/count]\n",
    "    \n",
    "    return subject_transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a32247c-1bc8-49c5-9f69-eaf704e05d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rmssd(subset):\n",
    "    rrInts = subset['rrInt'].tolist()\n",
    "    sum_of_squares = 0\n",
    "    for idx, rrInt in enumerate(rrInts):\n",
    "        if idx<len(rrInts)-1:\n",
    "            square_difference = (rrInt-rrInts[idx-1])**2\n",
    "            sum_of_squares+=square_difference\n",
    "    mean_sum = sum_of_squares/(len(rrInts)-1)\n",
    "    return np.sqrt(mean_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "134819a6-bdd8-4043-8501-20955d5e694c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_features(subset_list, current_weight = 0.25, prev_weight = 0.75):\n",
    "    subset_dfs = {}\n",
    "    for x, subset in enumerate(subset_list.itertuples()):\n",
    "        subset_dfs[x] = pd.read_parquet(os.path.normpath(str(Path(os.getcwd()).parents[1]) + '/mit-bih-time-subsets/'+str(subset.subjectID)+'/'+str(subset.subjectID)+\"-\"+str(x)+\".parquet\"))\n",
    "\n",
    "    calib_df = subset_dfs[0]\n",
    "\n",
    "    feature_dict = {}\n",
    "\n",
    "    props = find_proportions(classify_rr_ints(calib_df))\n",
    "    feature_dict['StoS'] = [props[0]]\n",
    "    feature_dict['StoR'] = [props[1]]\n",
    "    feature_dict['StoL'] = [props[2]]\n",
    "    feature_dict['RtoS'] = [props[3]]\n",
    "    feature_dict['RtoR'] = [props[4]]\n",
    "    feature_dict['RtoL'] = [props[5]]\n",
    "    feature_dict['LtoS'] = [props[6]]\n",
    "    feature_dict['LtoR'] = [props[7]]\n",
    "    feature_dict['LtoL'] = [props[8]]\n",
    "\n",
    "    feature_dict['std'] = [np.std(calib_df['rrInt'])]\n",
    "    feature_dict['cov'] = [feature_dict['std'][0]/np.mean(calib_df['rrInt'])]\n",
    "    feature_dict['range'] = [np.max(calib_df['rrInt'])-np.min(calib_df['rrInt'])]\n",
    "    #feature_dict['rmean'] = df['rmean'].tolist()\n",
    "    #feature_dict['rrv'] = df['rr_variance'].tolist()\n",
    "    feature_dict['rrInt_var'] = [calib_df['rrInt'].var()]\n",
    "    feature_dict['rmean_var'] = [calib_df['rmean'].var()]\n",
    "    feature_dict['rmssd'] = [extract_rmssd(calib_df)]\n",
    "    feature_dict['mad'] = [stats.median_abs_deviation(calib_df['rrInt'])]\n",
    "    feature_dict['iqr'] = [stats.iqr(calib_df['rrInt'])]\n",
    "\n",
    "    drr = np.diff(calib_df['rrInt'])\n",
    "    feature_dict['drrmean'] = [np.mean(drr)]\n",
    "    feature_dict['drrvar'] = [np.var(drr)]\n",
    "    \n",
    "    for key in subset_dfs:\n",
    "        if key>0:\n",
    "            current_subset = subset_dfs[key]\n",
    "            props = find_proportions(classify_rr_ints(current_subset))\n",
    "            feature_dict['StoS'].append(props[0]*current_weight + feature_dict['StoS'][key-1]*prev_weight)\n",
    "            feature_dict['StoR'].append(props[1]*current_weight + feature_dict['StoR'][key-1]*prev_weight)\n",
    "            feature_dict['StoL'].append(props[2]*current_weight + feature_dict['StoL'][key-1]*prev_weight)\n",
    "            feature_dict['RtoS'].append(props[3]*current_weight + feature_dict['RtoS'][key-1]*prev_weight)\n",
    "            feature_dict['RtoR'].append(props[4]*current_weight + feature_dict['RtoR'][key-1]*prev_weight)\n",
    "            feature_dict['RtoL'].append(props[5]*current_weight + feature_dict['RtoL'][key-1]*prev_weight)\n",
    "            feature_dict['LtoS'].append(props[6]*current_weight + feature_dict['LtoS'][key-1]*prev_weight)\n",
    "            feature_dict['LtoR'].append(props[7]*current_weight + feature_dict['LtoR'][key-1]*prev_weight)\n",
    "            feature_dict['LtoL'].append(props[8]*current_weight + feature_dict['LtoL'][key-1]*prev_weight)\n",
    "\n",
    "            feature_dict['std'].append(np.std(current_subset['rrInt'])*current_weight + feature_dict['std'][key-1]*prev_weight)\n",
    "            feature_dict['cov'].append((feature_dict['std'][key]/np.mean(current_subset['rrInt']))*current_weight + feature_dict['cov'][key-1]*prev_weight)\n",
    "            feature_dict['range'].append(np.max(current_subset['rrInt'])-np.min(current_subset['rrInt'])*current_weight + feature_dict['range'][key-1]*prev_weight)\n",
    "            #feature_dict['rmean'] = df['rmean'].tolist()\n",
    "            #feature_dict['rrv'] = df['rr_variance'].tolist()\n",
    "            feature_dict['rrInt_var'].append(current_subset['rrInt'].var()*current_weight + feature_dict['rrInt_var'][key-1]*prev_weight)\n",
    "            feature_dict['rmean_var'].append(current_subset['rmean'].var()*current_weight + feature_dict['rmean_var'][key-1]*prev_weight)\n",
    "            feature_dict['rmssd'].append(extract_rmssd(current_subset)*current_weight + feature_dict['rmssd'][key-1]*prev_weight)\n",
    "            feature_dict['mad'].append(stats.median_abs_deviation(current_subset['rrInt'])*current_weight + feature_dict['mad'][key-1]*prev_weight)\n",
    "            feature_dict['iqr'].append(stats.iqr(current_subset['rrInt'])*current_weight + feature_dict['iqr'][key-1]*prev_weight)\n",
    "\n",
    "            drr = np.diff(calib_df['rrInt'])\n",
    "            feature_dict['drrmean'].append(np.mean(drr)*current_weight + feature_dict['drrmean'][key-1]*prev_weight)\n",
    "            feature_dict['drrvar'].append(np.var(drr)*current_weight + feature_dict['drrvar'][key-1]*prev_weight)\n",
    "\n",
    "    feature_df = pd.DataFrame(data=feature_dict)\n",
    "    return pd.concat([subset_list, feature_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6159637a-f4e0-47d9-8111-3d4d8ceeed40",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_weight = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "462c6d84-0756-447c-8051-2ed4c574f63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   1 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=8)]: Done   3 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=8)]: Done   4 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 tasks      | elapsed:   24.0s\n",
      "[Parallel(n_jobs=8)]: Done   6 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=8)]: Done   7 tasks      | elapsed:   31.4s\n",
      "[Parallel(n_jobs=8)]: Done   8 tasks      | elapsed:   33.1s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  23 | elapsed:   40.9s remaining:   53.2s\n",
      "[Parallel(n_jobs=8)]: Done  12 out of  23 | elapsed:   46.5s remaining:   42.7s\n",
      "[Parallel(n_jobs=8)]: Done  14 out of  23 | elapsed:   50.2s remaining:   32.3s\n",
      "[Parallel(n_jobs=8)]: Done  16 out of  23 | elapsed:   59.8s remaining:   26.2s\n",
      "[Parallel(n_jobs=8)]: Done  18 out of  23 | elapsed:  1.0min remaining:   17.4s\n",
      "[Parallel(n_jobs=8)]: Done  20 out of  23 | elapsed:  1.1min remaining:   10.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  23 out of  23 | elapsed:  1.3min finished\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(str(Path(os.getcwd()).parents[1]) + '/mit-bih-time-features/'):\n",
    "    os.mkdir(str(Path(os.getcwd()).parents[1]) + '/mit-bih-time-features/')\n",
    "\n",
    "subset_lists = []\n",
    "for record in rlist:\n",
    "    subset_lists.append(pd.read_parquet(os.path.normpath(str(Path(os.getcwd()).parents[1]) + '/mit-bih-time-subsets/'+record+'_subset_list.parquet')))\n",
    "    \n",
    "features_list = Parallel(n_jobs=8, verbose=12)(\n",
    "    delayed(subset_features)(subset_list, current_weight, 1-current_weight)\n",
    "    for subset_list in subset_lists\n",
    ")\n",
    "\n",
    "for idx, record in enumerate(rlist):\n",
    "    features_list[idx].to_parquet(os.path.normpath(str(Path(os.getcwd()).parents[1]) + '/mit-bih-time-features/'+record+\".parquet\"))\n",
    "    \n",
    "print(\"Feature extraction complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc492292",
   "metadata": {
    "papermill": {
     "duration": 1.290393,
     "end_time": "2023-02-25T02:20:16.047768",
     "exception": false,
     "start_time": "2023-02-25T02:20:14.757375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca05c0ba5de40d19e776ba85da1ee62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_dfs = {}\n",
    "for record in tqdm(rlist):\n",
    "    feature_dfs[record] = pd.read_parquet(str(Path(os.getcwd()).parents[1]) + '/mit-bih-time-features/'+record+'.parquet')\n",
    "\n",
    "combined_features = pd.concat([feature_dfs[key][1:] for key in feature_dfs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be7bfc92",
   "metadata": {
    "papermill": {
     "duration": 0.105087,
     "end_time": "2023-02-25T02:20:16.157453",
     "exception": false,
     "start_time": "2023-02-25T02:20:16.052366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = combined_features[['StoS', 'StoR', 'StoL', 'RtoS', 'RtoR', 'RtoL', 'LtoS', 'LtoR', 'LtoL', 'std', 'cov', 'range', 'rrInt_var', 'rmean_var', 'rmssd', 'mad', 'iqr']]#, 'drrmean', 'drrvar']]\n",
    "y = combined_features['mappedLabel'].map({\"Non-Afib\": 0, \"Afib\": 1})\n",
    "groups = combined_features['subjectID'].astype('int64')\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "splits = list(logo.split(X, y, groups=groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8aa3ff85",
   "metadata": {
    "papermill": {
     "duration": 0.013836,
     "end_time": "2023-02-25T02:20:16.175323",
     "exception": false,
     "start_time": "2023-02-25T02:20:16.161487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.seterr(all='ignore')\n",
    "moving_accs = []\n",
    "\n",
    "if os.path.exists(f'saved_results_{current_weight}')==False:\n",
    "    os.mkdir(f'saved_results_{current_weight}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d54f2a18",
   "metadata": {
    "papermill": {
     "duration": 0.020048,
     "end_time": "2023-02-25T02:20:16.199212",
     "exception": false,
     "start_time": "2023-02-25T02:20:16.179164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def score_reporter(results, importances=True):\n",
    "    bestParams = None\n",
    "    maxScore = 0\n",
    "    for params, scores in results.items():\n",
    "        num_splits = scores['folds']\n",
    "        accuracy = [scores[f\"split{i}_accuracy\"] for i in range(num_splits)]\n",
    "        print(params, np.mean(accuracy))\n",
    "        \n",
    "        if (np.mean(accuracy) > maxScore):\n",
    "            bestParams = params\n",
    "            maxScore = np.mean(accuracy)\n",
    "            \n",
    "    bestScores = results[bestParams]\n",
    "    num_splits = bestScores['folds']\n",
    "    accuracy = [bestScores[f\"split{i}_accuracy\"] for i in range(num_splits)]\n",
    "    sensitivity = [bestScores[f\"split{i}_sensitivity\"] for i in range(num_splits)]\n",
    "    specificity = [bestScores[f\"split{i}_specificity\"] for i in range(num_splits)]\n",
    "    precision = [bestScores[f\"split{i}_precision\"] for i in range(num_splits)]\n",
    "    f1_score = [bestScores[f\"split{i}_f1_score\"] for i in range(num_splits)]\n",
    "    if importances:\n",
    "        feature_importances = [list(bestScores[f\"split{i}_feature_importances\"].values()) for i in range(num_splits)]\n",
    "    \n",
    "        avg_importances = np.mean(np.array(feature_importances), axis=0)\n",
    "        feature_names = list(bestScores[\"split0_feature_importances\"].keys())[0]\n",
    "        mapped_importances = {name: rank for name, rank in zip(feature_names, avg_importances.flatten())}\n",
    "    \n",
    "    print(f\"The best parameters were {bestParams}\")\n",
    "    print(f\"Accuracy for each fold: {accuracy}\")\n",
    "    print(f\"Mean accuracy: {np.nanmean(accuracy)}\")\n",
    "    print(f\"Std accuracy: {np.nanstd(accuracy)}\")\n",
    "    print(f\"Sensitivity for each fold: {sensitivity}\")\n",
    "    print(f\"Mean sensitivity: {np.nanmean(sensitivity)}\")\n",
    "    print(f\"Std sensitivity: {np.nanstd(sensitivity)}\")\n",
    "    print(f\"Specificity for each fold: {specificity}\")\n",
    "    print(f\"Mean specificity: {np.nanmean(specificity)}\")\n",
    "    print(f\"Std specificity: {np.nanstd(specificity)}\")\n",
    "    print(f\"Precision for each fold: {precision}\")\n",
    "    print(f\"Mean precision: {np.nanmean(precision)}\")\n",
    "    print(f\"Std precision: {np.nanstd(precision)}\")\n",
    "    print(f\"F1-score for each fold: {f1_score}\")\n",
    "    print(f\"Mean F1-score: {np.nanmean(f1_score)}\")\n",
    "    print(f\"Std F1-score: {np.nanstd(f1_score)}\")\n",
    "    if importances:\n",
    "        print(\"Average feature importances: \")\n",
    "        print(mapped_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4978575c-5e37-4cfc-b5fa-4fc035a39582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_parallel(clf, X, y, train, test, **fit_params):\n",
    "    np.seterr(all='ignore')\n",
    "    \n",
    "    X_train = X.iloc[train]\n",
    "    y_train = y.iloc[train]\n",
    "\n",
    "    X_test = X.iloc[test]\n",
    "    y_test = y.iloc[test]\n",
    "    \n",
    "    cloned_clf = clone(clf)\n",
    "    cloned_clf.fit(X_train, y_train)\n",
    "\n",
    "    pred_values = cloned_clf.predict(X_test)\n",
    "\n",
    "    cm = confusion_matrix(y_test.values.reshape(y_test.shape[0]), pred_values)\n",
    "    sensitivity = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "    specificity = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "    precision = (cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "\n",
    "    results_dict = {\n",
    "        \"accuracy\": accuracy_score(y_test, pred_values),\n",
    "        \"sensitivity\": sensitivity,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision,\n",
    "        \"f1_score\": (2*precision*sensitivity)/(precision+sensitivity)\n",
    "    }\n",
    "    \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ac2f2ab-b905-425d-b871-3669177de3f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit_xgboost_parallel(clf, X, y, train, test, **fit_params):\n",
    "    np.seterr(all='ignore')\n",
    "    \n",
    "    X_train = X.iloc[train]\n",
    "    y_train = y.iloc[train]\n",
    "\n",
    "    X_test = X.iloc[test]\n",
    "    y_test = y.iloc[test]\n",
    "    \n",
    "    cloned_clf = clone(clf)\n",
    "    cloned_clf.fit(X_train, y_train)\n",
    "\n",
    "    pred_values = cloned_clf.predict(X_test)\n",
    "\n",
    "    cm = confusion_matrix(y_test.values.reshape(y_test.shape[0]), pred_values)\n",
    "    sensitivity = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "    specificity = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "    precision = (cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "\n",
    "    results_dict = {\n",
    "        \"accuracy\": accuracy_score(y_test, pred_values),\n",
    "        \"sensitivity\": sensitivity,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision,\n",
    "        \"f1_score\": (2*precision*sensitivity)/(precision+sensitivity),\n",
    "        \"feature_importances\": {A: B for A, B in zip(cloned_clf.feature_names_in_, cloned_clf.feature_importances_)}\n",
    "    }\n",
    "    \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ca40cd1-059d-4be9-96f2-8932e73923f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit_catboost_parallel(clf, X, y, train, test, **fit_params):\n",
    "    np.seterr(all='ignore')\n",
    "    \n",
    "    X_train = X.iloc[train]\n",
    "    y_train = y.iloc[train]\n",
    "\n",
    "    X_test = X.iloc[test]\n",
    "    y_test = y.iloc[test]\n",
    "    \n",
    "    cloned_clf = clone(clf)\n",
    "    cloned_clf.fit(X_train, y_train)\n",
    "\n",
    "    pred_values = cloned_clf.predict(X_test)\n",
    "\n",
    "    cm = confusion_matrix(y_test.values.reshape(y_test.shape[0]), pred_values)\n",
    "    sensitivity = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "    specificity = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "    precision = (cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "\n",
    "    results_dict = {\n",
    "        \"accuracy\": accuracy_score(y_test, pred_values),\n",
    "        \"sensitivity\": sensitivity,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision,\n",
    "        \"f1_score\": (2*precision*sensitivity)/(precision+sensitivity),\n",
    "        \"feature_importances\": {A: B for A, B in zip(cloned_clf.feature_names_, cloned_clf.feature_importances_)}\n",
    "    }\n",
    "    \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcdc9289-0554-40a0-906a-1612251fe6d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit_lightgbm_parallel(clf, X, y, train, test, **fit_params):\n",
    "    np.seterr(all='ignore')\n",
    "    \n",
    "    X_train = X.iloc[train]\n",
    "    y_train = y.iloc[train]\n",
    "\n",
    "    X_test = X.iloc[test]\n",
    "    y_test = y.iloc[test]\n",
    "    \n",
    "    cloned_clf = clone(clf)\n",
    "    cloned_clf.fit(X_train,y_train,eval_set=[(X_test,y_test),(X_train,y_train)], \n",
    "                   eval_metric='logloss')\n",
    "\n",
    "    pred_values = cloned_clf.predict(X_test)\n",
    "\n",
    "    cm = confusion_matrix(y_test.values.reshape(y_test.shape[0]), pred_values)\n",
    "    sensitivity = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "    specificity = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "    precision = (cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "\n",
    "    results_dict = {\n",
    "        \"accuracy\": accuracy_score(y_test, pred_values),\n",
    "        \"sensitivity\": sensitivity,\n",
    "        \"specificity\": specificity,\n",
    "        \"precision\": precision,\n",
    "        \"f1_score\": (2*precision*sensitivity)/(precision+sensitivity),\n",
    "        \"feature_importances\": {A: B for A, B in zip(cloned_clf.feature_name_, cloned_clf.feature_importances_)}\n",
    "    }\n",
    "    \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77db9518-c15a-4d53-b7dc-d6cf05df25eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with 1 different parameter combinations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423f7c63d3184120955a372a9914a643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logistic regression\n",
    "folder = './joblib_memmap'\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "dump(X, os.path.join(folder, 'X'))\n",
    "X_memmap = load(os.path.join(folder, 'X'), mmap_mode='r')\n",
    "dump(y, os.path.join(folder, 'y'))\n",
    "y_memmap = load(os.path.join(folder, 'y'), mmap_mode='r')\n",
    "\n",
    "#num_combinations = 30\n",
    "params = {\n",
    "    \"solver\": [\"liblinear\"]\n",
    "}\n",
    "param_grid = ParameterGrid(params)\n",
    "print(f'Fitting with {len(param_grid)} different parameter combinations')\n",
    "results = {}\n",
    "\n",
    "with tqdm(param_grid) as pbar:\n",
    "    for fit_params in pbar:\n",
    "        pbar.set_description(f'Fitting parameter combination: {fit_params}')\n",
    "        \n",
    "        clf = LogisticRegression(max_iter=3000,\n",
    "                                 **fit_params)\n",
    "        fold_results = Parallel(n_jobs=8)(\n",
    "            delayed(fit_parallel)(clf, X_memmap, y_memmap, train, test, **fit_params)\n",
    "            for (train, test) in splits\n",
    "        )\n",
    "        \n",
    "        current_results = {}\n",
    "        for i, result in enumerate(fold_results):\n",
    "            current_results[f\"split{i}_accuracy\"] = result[\"accuracy\"]\n",
    "            current_results[f\"split{i}_sensitivity\"] = result[\"sensitivity\"]\n",
    "            current_results[f\"split{i}_specificity\"] = result[\"specificity\"]\n",
    "            current_results[f\"split{i}_precision\"] = result[\"precision\"]\n",
    "            current_results[f\"split{i}_f1_score\"] = result[\"f1_score\"]\n",
    "        results[tuple(sorted(fit_params.items()))] = current_results\n",
    "        results[tuple(sorted(fit_params.items()))]['folds'] = len(splits)\n",
    "\n",
    "with open(f'saved_results_{current_weight}/lr_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "712770d8-e73b-4acc-a88d-7432e3d23a4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('solver', 'liblinear'),) 0.8413063587521947\n",
      "The best parameters were (('solver', 'liblinear'),)\n",
      "Accuracy for each fold: [0.8962406015037594, 0.8977769148626347, 0.9746606334841629, 0.737085906793936, 0.9056651174475568, 0.9160097323600973, 0.8031831427930958, 0.9787199214274022, 0.804460518384569, 0.8370986920332937, 0.8832188420019627, 0.9412476239847936, 0.6979302832244009, 0.8590254367146798, 0.44039900249376557, 0.7831839521980367, 0.9476907796722397, 0.8788341429562804, 0.6056580815250456, 0.8966701902748414, 0.8727402716780717, 0.9272123225611598, 0.8653341409246921]\n",
      "Mean accuracy: 0.8413063587521947\n",
      "Std accuracy: 0.12216752481793575\n",
      "Sensitivity for each fold: [0.8982980489829805, 0.9721090168110036, 0.976905311778291, 0.7327153927974472, 0.9751243781094527, 0.9348737238044063, 0.9230769230769231, 0.9792967466316136, 0.872324446113406, 0.8352226720647773, 0.7289156626506024, 0.9443374759320847, 0.6056399132321041, nan, nan, 0.9238728750923872, 0.9578754578754579, 0.966804979253112, 0.5520555258942872, 0.9637488947833776, 0.9613186813186814, 0.9365079365079365, 0.983794466403162]\n",
      "Mean sensitivity: 0.8868961204339759\n",
      "Std sensitivity: 0.12298802630703384\n",
      "Specificity for each fold: [0.7272727272727273, 0.6594528378930176, 0.8666666666666667, 0.7900552486187845, 0.8676899164561881, 0.7350515463917526, 0.7615163872526809, 0.8260869565217391, 0.7723721590909091, 0.9245283018867925, 0.8890145944111325, 0.7027027027027027, 0.7910284463894968, 0.8590254367146798, 0.44039900249376557, 0.7260726072607261, 0.9032830523513753, 0.8519391083725988, 0.7751054852320675, 0.698379508625196, 0.8459286854709952, 0.7766233766233767, 0.8247017353579176]\n",
      "Mean specificity: 0.7832563691329256\n",
      "Std specificity: 0.10079704306074767\n",
      "Precision for each fold: [0.996316758747698, 0.9014999409472068, 0.9971711456859972, 0.976904376012966, 0.8011678832116789, 0.9713041536400179, 0.5735889819065623, 0.9993293091884641, 0.644382801664355, 0.9980648282535075, 0.19787408013082583, 0.9959387114639099, 0.7451294368828396, 0.0, 0.0, 0.5779010633379565, 0.9773671096345515, 0.6662581699346405, 0.8858427928892697, 0.9042641446822631, 0.6538116591928251, 0.9854901299139531, 0.6581173982020095]\n",
      "Mean precision: 0.7438141250227608\n",
      "Std precision: 0.30266742275869485\n",
      "F1-score for each fold: [0.944771883868151, 0.9354739873766774, 0.9869342043863742, 0.8373708431015022, 0.8796281455361435, 0.9527408137560922, 0.7075283144570287, 0.9892116182572613, 0.7412252712188896, 0.909411505400044, 0.3112540192926045, 0.9694519317160827, 0.6681823620916596, nan, nan, 0.7110352673492606, 0.9675231243576569, 0.788875453446191, 0.6802072198010032, 0.9330594076356789, 0.7782918149466193, 0.9603748766853009, 0.7886565272496832]\n",
      "Mean F1-score: 0.8305337424728526\n",
      "Std F1-score: 0.1581082307365198\n"
     ]
    }
   ],
   "source": [
    "score_reporter(results, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c22095e6-daf3-46cd-8ab0-2ec9edc32e1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with 1 different parameter combinations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76743d2f29e44d5a24036d038f96e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LDA\n",
    "folder = './joblib_memmap'\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "dump(X, os.path.join(folder, 'X'))\n",
    "X_memmap = load(os.path.join(folder, 'X'), mmap_mode='r')\n",
    "dump(y, os.path.join(folder, 'y'))\n",
    "y_memmap = load(os.path.join(folder, 'y'), mmap_mode='r')\n",
    "\n",
    "#num_combinations = 30\n",
    "params = {\n",
    "    \"solver\": [\"lsqr\"]\n",
    "}\n",
    "param_grid = ParameterGrid(params)\n",
    "print(f'Fitting with {len(param_grid)} different parameter combinations')\n",
    "results = {}\n",
    "\n",
    "with tqdm(param_grid) as pbar:\n",
    "    for fit_params in pbar:\n",
    "        pbar.set_description(f'Fitting parameter combination: {fit_params}')\n",
    "        \n",
    "        clf = LinearDiscriminantAnalysis(**fit_params)\n",
    "        fold_results = Parallel(n_jobs=8)(\n",
    "            delayed(fit_parallel)(clf, X_memmap, y_memmap, train, test, **fit_params)\n",
    "            for (train, test) in splits\n",
    "        )\n",
    "        \n",
    "        current_results = {}\n",
    "        for i, result in enumerate(fold_results):\n",
    "            current_results[f\"split{i}_accuracy\"] = result[\"accuracy\"]\n",
    "            current_results[f\"split{i}_sensitivity\"] = result[\"sensitivity\"]\n",
    "            current_results[f\"split{i}_specificity\"] = result[\"specificity\"]\n",
    "            current_results[f\"split{i}_precision\"] = result[\"precision\"]\n",
    "            current_results[f\"split{i}_f1_score\"] = result[\"f1_score\"]\n",
    "        results[tuple(sorted(fit_params.items()))] = current_results\n",
    "        results[tuple(sorted(fit_params.items()))]['folds'] = len(splits)\n",
    "\n",
    "with open(f'saved_results_{current_weight}/lda_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4067b5b5-fbf0-4c28-bd41-7f76d78d036f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('solver', 'lsqr'),) 0.8213748233864019\n",
      "The best parameters were (('solver', 'lsqr'),)\n",
      "Accuracy for each fold: [0.8961038961038961, 0.8960295116978934, 0.9800904977375565, 0.8141493542953397, 0.8789096847129757, 0.9090024330900244, 0.7604797130688187, 0.959895236536258, 0.7666063893911995, 0.79944510503369, 0.8379675062697634, 0.9405564195610852, 0.6958605664488018, 0.7025743181121668, 0.4374064837905237, 0.7881988903115663, 0.9382552557523589, 0.7464260929909785, 0.6121476373960657, 0.8789640591966174, 0.8748850985599019, 0.9234370280881908, 0.8542297597415708]\n",
      "Mean accuracy: 0.8213748233864019\n",
      "Std accuracy: 0.12289545949238502\n",
      "Sensitivity for each fold: [0.8978829389788294, 0.9649770759042282, 0.9816782140107775, 0.8112748822367422, 0.98045486851457, 0.9281031703385276, 0.9204693611473272, 0.9604009201445941, 0.8790837401426962, 0.7967611336032389, 0.7289156626506024, 0.945387712235253, 0.6392624728850326, nan, nan, 0.9722838137472284, 0.9637769637769638, 0.9353882631890931, 0.5658035237586759, 0.960919540229885, 0.9547252747252747, 0.9345839345839346, 0.9699604743083003]\n",
      "Mean sensitivity: 0.8900997114815131\n",
      "Std sensitivity: 0.11411773853593171\n",
      "Specificity for each fold: [0.75, 0.6749693752552062, 0.9037037037037037, 0.848987108655617, 0.8233922673401982, 0.7257731958762886, 0.7048784171575291, 0.8260869565217391, 0.7134232954545454, 0.9245283018867925, 0.8420635818531508, 0.5675675675675675, 0.7529540481400437, 0.7025743181121668, 0.4374064837905237, 0.7134713471347135, 0.8269742679680568, 0.6886553098948894, 0.7586497890295358, 0.6366962885520125, 0.8507184672698244, 0.7428571428571429, 0.8145336225596529]\n",
      "Mean specificity: 0.7491680372426479\n",
      "Std specificity: 0.10727014316161138\n",
      "Precision for each fold: [0.9966211027491937, 0.9049325211990923, 0.9979652527782126, 0.9848736395498986, 0.7521810250817884, 0.9701190743653112, 0.5201375245579568, 0.9993161224140878, 0.5919089759797724, 0.9979716024340771, 0.14774114774114774, 0.9941100681023376, 0.7230127576054955, 0.0, 0.0, 0.5793878000440431, 0.9604542689109714, 0.4787621359223301, 0.8811057992101434, 0.8866046663403492, 0.6593806921675774, 0.9832995951417004, 0.6420722135007849]\n",
      "Mean precision: 0.7239981732954901\n",
      "Std precision: 0.31214581290680027\n",
      "F1-score for each fold: [0.9446789925753385, 0.9339907550077042, 0.9897547345544863, 0.8896850524912515, 0.8512804689910521, 0.9486461251167133, 0.6646791150164758, 0.9794721407624634, 0.7074644907827138, 0.8860873480414228, 0.24568527918781724, 0.9691369101022789, 0.6785632051577251, nan, nan, 0.726093555954188, 0.9621127475876079, 0.633353401565322, 0.6891002194586685, 0.9222674813306178, 0.7800323217812893, 0.9583230579531442, 0.7726700251889167]\n",
      "Mean F1-score: 0.815860829933676\n",
      "Std F1-score: 0.17354385133539665\n"
     ]
    }
   ],
   "source": [
    "score_reporter(results, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cbc6551-0cd6-4c0b-8712-30b054877be9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with 1 different parameter combinations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74929030383f4d8b86e91e31e9d8df0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ari/mambaforge/envs/afib/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/ari/mambaforge/envs/afib/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/ari/mambaforge/envs/afib/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/ari/mambaforge/envs/afib/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/ari/mambaforge/envs/afib/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/ari/mambaforge/envs/afib/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/ari/mambaforge/envs/afib/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/ari/mambaforge/envs/afib/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/ari/mambaforge/envs/afib/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/ari/mambaforge/envs/afib/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/ari/mambaforge/envs/afib/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/ari/mambaforge/envs/afib/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/ari/mambaforge/envs/afib/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/ari/mambaforge/envs/afib/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/ari/mambaforge/envs/afib/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/ari/mambaforge/envs/afib/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/ari/mambaforge/envs/afib/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/ari/mambaforge/envs/afib/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/ari/mambaforge/envs/afib/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/ari/mambaforge/envs/afib/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/ari/mambaforge/envs/afib/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/ari/mambaforge/envs/afib/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/ari/mambaforge/envs/afib/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "# QDA\n",
    "folder = './joblib_memmap'\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "dump(X, os.path.join(folder, 'X'))\n",
    "X_memmap = load(os.path.join(folder, 'X'), mmap_mode='r')\n",
    "dump(y, os.path.join(folder, 'y'))\n",
    "y_memmap = load(os.path.join(folder, 'y'), mmap_mode='r')\n",
    "\n",
    "#num_combinations = 30\n",
    "params = {\n",
    "    \"fake\": [\"param\"]\n",
    "}\n",
    "param_grid = ParameterGrid(params)\n",
    "print(f'Fitting with {len(param_grid)} different parameter combinations')\n",
    "results = {}\n",
    "\n",
    "with tqdm(param_grid) as pbar:\n",
    "    for fit_params in pbar:\n",
    "        pbar.set_description(f'Fitting parameter combination: {fit_params}')\n",
    "        \n",
    "        clf = QuadraticDiscriminantAnalysis()\n",
    "        fold_results = Parallel(n_jobs=8)(\n",
    "            delayed(fit_parallel)(clf, X_memmap, y_memmap, train, test, **fit_params)\n",
    "            for (train, test) in splits\n",
    "        )\n",
    "        \n",
    "        current_results = {}\n",
    "        for i, result in enumerate(fold_results):\n",
    "            current_results[f\"split{i}_accuracy\"] = result[\"accuracy\"]\n",
    "            current_results[f\"split{i}_sensitivity\"] = result[\"sensitivity\"]\n",
    "            current_results[f\"split{i}_specificity\"] = result[\"specificity\"]\n",
    "            current_results[f\"split{i}_precision\"] = result[\"precision\"]\n",
    "            current_results[f\"split{i}_f1_score\"] = result[\"f1_score\"]\n",
    "        results[tuple(sorted(fit_params.items()))] = current_results\n",
    "        results[tuple(sorted(fit_params.items()))]['folds'] = len(splits)\n",
    "\n",
    "with open(f'saved_results_{current_weight}/qda_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7070378-f6e4-4c65-98dd-c696a504a5cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('fake', 'param'),) 0.7334793609564302\n",
      "The best parameters were (('fake', 'param'),)\n",
      "Accuracy for each fold: [0.5546138072453862, 0.7785651878458402, 0.26349924585218704, 0.3163952835485682, 0.753548549177239, 0.8387347931873479, 0.7312261824702981, 0.129153707644459, 0.8332730560578662, 0.7592812789007795, 0.9694689783011667, 0.9142906514601693, 0.6916122004357298, 0.91955255899479, 0.9840399002493766, 0.9375800256081946, 0.9102797550074491, 0.7236641221374046, 0.7095923747718516, 0.8442124735729387, 0.8800939638443468, 0.6925400181214135, 0.734807187563093]\n",
      "Mean accuracy: 0.7334793609564302\n",
      "Std accuracy: 0.2199550319782928\n",
      "Sensitivity for each fold: [0.5491905354919053, 0.7311512990320937, 0.24926866820631255, 0.26075064579851087, 0.3251599147121535, 0.8260075228371843, 0.13081269013472405, 0.1258626355570161, 0.5636500187758168, 0.7546558704453441, 0.24397590361445784, 0.9182566077367408, 0.4943600867678959, nan, nan, 0.8203991130820399, 0.9224664224664225, 0.04386484884410195, 0.9026962092899092, 0.9819628647214854, 0.9564835164835165, 0.6791726791726792, 0.03517786561264822]\n",
      "Mean sensitivity: 0.5483488532753789\n",
      "Std sensitivity: 0.3229034770816612\n",
      "Specificity for each fold: [1.0, 0.930583911800735, 0.9481481481481482, 0.990791896869245, 0.987759860112687, 0.9608247422680413, 0.9398882344056789, 1.0, 0.9607599431818182, 0.9748427672955975, 0.9967190858694422, 0.6081081081081081, 0.8905908096280087, 0.91955255899479, 0.9840399002493766, 0.9851485148514851, 0.8571428571428571, 0.9314969191736137, 0.09915611814345991, 0.4370099320439101, 0.8569717935071847, 0.9090909090909091, 0.9747830802603037]\n",
      "Mean specificity: 0.8758004387454521\n",
      "Std specificity: 0.21014680643235328\n",
      "Precision for each fold: [1.0, 0.9712400609034004, 0.9956949569495694, 0.9970947123765252, 0.9355828220858896, 0.9950802692905231, 0.43061516452074394, 1.0, 0.8716608594657376, 0.9992852037169406, 0.7363636363636363, 0.9945023696682465, 0.8200791651673264, 0.0, 0.0, 0.9573091849935317, 0.9657008947592671, 0.16371681415929204, 0.7600584400988987, 0.8375565610859729, 0.6693325130729006, 0.9918051978459377, 0.3236363636363636]\n",
      "Mean precision: 0.7572310952243785\n",
      "Std precision: 0.32606104210839315\n",
      "F1-score for each fold: [0.7090032154340836, 0.8342657850759282, 0.3987193695357714, 0.4133943628041436, 0.4825949367088608, 0.90269540196136, 0.2006666666666667, 0.22358435493286632, 0.6846066134549601, 0.8599108103952022, 0.3665158371040724, 0.9548598471059336, 0.6168629043172283, nan, nan, 0.8835820895522387, 0.9435886761032474, 0.06919121084618982, 0.8252593044539354, 0.904029304029304, 0.7875497647484617, 0.8062428625808907, 0.06345811051693404]\n",
      "Mean F1-score: 0.6157419727775372\n",
      "Std F1-score: 0.2917833835341899\n"
     ]
    }
   ],
   "source": [
    "score_reporter(results, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54ea3294-7b77-4796-b149-d71236a6da49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with 1 different parameter combinations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "204c334a1891452b9a41d4e97e072ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# KNN\n",
    "folder = './joblib_memmap'\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "dump(X, os.path.join(folder, 'X'))\n",
    "X_memmap = load(os.path.join(folder, 'X'), mmap_mode='r')\n",
    "dump(y, os.path.join(folder, 'y'))\n",
    "y_memmap = load(os.path.join(folder, 'y'), mmap_mode='r')\n",
    "\n",
    "#num_combinations = 30\n",
    "params = {\n",
    "    \"n_neighbors\": [9]\n",
    "}\n",
    "param_grid = ParameterGrid(params)\n",
    "print(f'Fitting with {len(param_grid)} different parameter combinations')\n",
    "results = {}\n",
    "\n",
    "with tqdm(param_grid) as pbar:\n",
    "    for fit_params in pbar:\n",
    "        pbar.set_description(f'Fitting parameter combination: {fit_params}')\n",
    "        \n",
    "        clf = KNeighborsClassifier(**fit_params)\n",
    "        fold_results = Parallel(n_jobs=8)(\n",
    "            delayed(fit_parallel)(clf, X_memmap, y_memmap, train, test, **fit_params)\n",
    "            for (train, test) in splits\n",
    "        )\n",
    "        \n",
    "        current_results = {}\n",
    "        for i, result in enumerate(fold_results):\n",
    "            current_results[f\"split{i}_accuracy\"] = result[\"accuracy\"]\n",
    "            current_results[f\"split{i}_sensitivity\"] = result[\"sensitivity\"]\n",
    "            current_results[f\"split{i}_specificity\"] = result[\"specificity\"]\n",
    "            current_results[f\"split{i}_precision\"] = result[\"precision\"]\n",
    "            current_results[f\"split{i}_f1_score\"] = result[\"f1_score\"]\n",
    "        results[tuple(sorted(fit_params.items()))] = current_results\n",
    "        results[tuple(sorted(fit_params.items()))]['folds'] = len(splits)\n",
    "\n",
    "with open(f'saved_results_{current_weight}/knn_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36e1fced-c1c1-4f39-95f0-a9afe36191d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('n_neighbors', 9),) 0.8460586655107755\n",
      "The best parameters were (('n_neighbors', 9),)\n",
      "Accuracy for each fold: [0.8120300751879699, 0.9268032229880594, 0.9647058823529412, 0.6035934868051657, 0.905790729807813, 0.9148418491484185, 0.8206680116565792, 0.8963823866426583, 0.8378541289933695, 0.786761791518034, 0.9102606040780722, 0.8873336789355452, 0.7, 0.8351210542445602, 0.7719700748129675, 0.8218096457533077, 0.9309716934282404, 0.9326856349757113, 0.5390387345366051, 0.9171511627906976, 0.9165560208354612, 0.9090909090909091, 0.9179285281647487]\n",
      "Mean accuracy: 0.8460586655107755\n",
      "Std accuracy: 0.10572673216004856\n",
      "Sensitivity for each fold: [0.8114016881140169, 0.9668874172185431, 0.9658198614318707, 0.5792432760978574, 0.8638948116560057, 0.9220849005910801, 0.8735332464146024, 0.8966480446927374, 0.7510326699211416, 0.7831309041835358, 0.6174698795180723, 0.8867495186416944, 0.49349240780911063, nan, nan, 0.8702882483370288, 0.9287749287749287, 0.9561351511558981, 0.41898024559530167, 0.9359858532272325, 0.9578021978021978, 0.9108545775212442, 0.9754940711462451]\n",
      "Mean sensitivity: 0.8269382809452546\n",
      "Std sensitivity: 0.16002047088309637\n",
      "Specificity for each fold: [0.8636363636363636, 0.7982850142915475, 0.9111111111111111, 0.8987108655616943, 0.9286963279580338, 0.845360824742268, 0.8022957257211901, 0.8260869565217391, 0.87890625, 0.9559748427672956, 0.9212580608666139, 0.9324324324324325, 0.9083150984682713, 0.8351210542445602, 0.7719700748129675, 0.8021302130213022, 0.940550133096717, 0.9255164914824212, 0.9185654008438818, 0.8614741244119185, 0.9040713145290048, 0.8805194805194805, 0.8981832971800434]\n",
      "Mean specificity: 0.8786596286182984\n",
      "Std specificity: 0.051071667720995445\n",
      "Precision for each fold: [0.9979577944179714, 0.9389067524115756, 0.9980906921241051, 0.9857770881820532, 0.8688348820586133, 0.9828178694158075, 0.605604097619765, 0.9992675334187877, 0.7457121551081283, 0.9987951807228915, 0.22752497225305215, 0.9990140011831986, 0.8444691907943578, 0.0, 0.0, 0.640990745781165, 0.9855322824443965, 0.7969367588932806, 0.9420768307322929, 0.9523209787693415, 0.7513793103448276, 0.9919678714859438, 0.7666977322149736]\n",
      "Mean precision: 0.7835075965381099\n",
      "Std precision: 0.3004954993765419\n",
      "F1-score for each fold: [0.8950621994962985, 0.9526916802610116, 0.9816901408450704, 0.729709035222052, 0.8663578047042052, 0.9514832270584974, 0.7153024911032029, 0.9451805663808781, 0.7483629560336763, 0.8779122541603631, 0.33252230332522303, 0.9395400593471811, 0.622946330777656, nan, nan, 0.738244514106583, 0.9563122053431116, 0.8693074642953382, 0.5800073909830007, 0.9440827610808884, 0.8421256038647342, 0.9496823804747576, 0.858584101582884]\n",
      "Mean F1-score: 0.8236717843069815\n",
      "Std F1-score: 0.15766876636132843\n"
     ]
    }
   ],
   "source": [
    "score_reporter(results, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06af1de2-de9c-4306-8f77-87b971085597",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with 1 different parameter combinations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ab488e15dbb47ae90ce5636b32cc558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Decision tree\n",
    "folder = './joblib_memmap'\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "dump(X, os.path.join(folder, 'X'))\n",
    "X_memmap = load(os.path.join(folder, 'X'), mmap_mode='r')\n",
    "dump(y, os.path.join(folder, 'y'))\n",
    "y_memmap = load(os.path.join(folder, 'y'), mmap_mode='r')\n",
    "\n",
    "#num_combinations = 30\n",
    "params = {\n",
    "    \"max_depth\": [None]\n",
    "}\n",
    "param_grid = ParameterGrid(params)\n",
    "print(f'Fitting with {len(param_grid)} different parameter combinations')\n",
    "results = {}\n",
    "\n",
    "with tqdm(param_grid) as pbar:\n",
    "    for fit_params in pbar:\n",
    "        pbar.set_description(f'Fitting parameter combination: {fit_params}')\n",
    "        \n",
    "        clf = DecisionTreeClassifier(**fit_params)\n",
    "        \n",
    "        fold_results = []\n",
    "        for (train, test) in tqdm(splits, leave=False):\n",
    "            X_train = X.iloc[train]\n",
    "            y_train = y.iloc[train]\n",
    "\n",
    "            X_test = X.iloc[test]\n",
    "            y_test = y.iloc[test]\n",
    "\n",
    "            cloned_clf = clone(clf)\n",
    "            cloned_clf.fit(X_train, y_train)\n",
    "\n",
    "            pred_values = cloned_clf.predict(X_test)\n",
    "\n",
    "            cm = confusion_matrix(y_test.values.reshape(y_test.shape[0]), pred_values)\n",
    "            sensitivity = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "            specificity = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "            precision = (cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "\n",
    "            results_dict = {\n",
    "                \"accuracy\": accuracy_score(y_test, pred_values),\n",
    "                \"sensitivity\": sensitivity,\n",
    "                \"specificity\": specificity,\n",
    "                \"precision\": precision,\n",
    "                \"f1_score\": (2*precision*sensitivity)/(precision+sensitivity)\n",
    "            }\n",
    "\n",
    "            fold_results.append(results_dict)\n",
    "        \n",
    "        current_results = {}\n",
    "        for i, result in enumerate(fold_results):\n",
    "            current_results[f\"split{i}_accuracy\"] = result[\"accuracy\"]\n",
    "            current_results[f\"split{i}_sensitivity\"] = result[\"sensitivity\"]\n",
    "            current_results[f\"split{i}_specificity\"] = result[\"specificity\"]\n",
    "            current_results[f\"split{i}_precision\"] = result[\"precision\"]\n",
    "            current_results[f\"split{i}_f1_score\"] = result[\"f1_score\"]\n",
    "        results[tuple(sorted(fit_params.items()))] = current_results\n",
    "        results[tuple(sorted(fit_params.items()))]['folds'] = len(splits)\n",
    "\n",
    "with open(f'saved_results_{current_weight}/dt_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d64dff9-9f28-440d-9a2a-b8c76148b2eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('max_depth', None),) 0.850184437013619\n",
      "The best parameters were (('max_depth', None),)\n",
      "Accuracy for each fold: [0.8318523581681476, 0.8826327541015435, 0.9717948717948718, 0.7230488489612578, 0.9089310388142193, 0.882043795620438, 0.7468056489576328, 0.9711900474709445, 0.812537673297167, 0.8606156691769058, 0.8879075346199978, 0.9466044582685329, 0.7075163398692811, 0.7627949739503525, 0.773067331670823, 0.897247119078105, 0.9402416818407549, 0.8108258154059681, 0.5696613263029812, 0.8969344608879493, 0.9020529057297518, 0.953035336756267, 0.9149000605693519]\n",
      "Mean accuracy: 0.850184437013619\n",
      "Std accuracy: 0.09747489400151495\n",
      "Sensitivity for each fold: [0.8310502283105022, 0.8839786041772797, 0.9739799846035412, 0.7166084181735298, 0.9658848614072495, 0.8780225685115529, 0.6079965232507606, 0.9715741045021361, 0.8167480285392414, 0.860863697705803, 0.6295180722891566, 0.9485384211447576, 0.5149674620390455, nan, nan, 0.9076127124907613, 0.9595034595034595, 0.967397747480735, 0.45381740523224773, 0.9158267020335986, 0.9556043956043956, 0.9562289562289562, 0.9739130434782609]\n",
      "Mean sensitivity: 0.8423635903193796\n",
      "Std sensitivity: 0.15750798855394782\n",
      "Specificity for each fold: [0.8977272727272727, 0.8783176806859943, 0.8666666666666667, 0.8011049723756906, 0.8777928890615893, 0.9206185567010309, 0.7950460655490107, 0.8695652173913043, 0.810546875, 0.8490566037735849, 0.8976128521325942, 0.7972972972972973, 0.9017505470459518, 0.7627949739503525, 0.773067331670823, 0.893039303930393, 0.8562555456965395, 0.762957593330917, 0.9358649789029536, 0.8410872974385781, 0.8858435337945716, 0.9012987012987013, 0.8946583514099783]\n",
      "Mean specificity: 0.8552161351231216\n",
      "Std specificity: 0.05104087672535612\n",
      "Precision for each fold: [0.9985037406483791, 0.9588340931067827, 0.9971626733921816, 0.9776119402985075, 0.8120705109052884, 0.990663271492664, 0.5076197387518142, 0.9994929006085193, 0.6708821714990747, 0.9962517569889114, 0.18761220825852784, 0.9972396025027604, 0.8409493446687921, 0.0, 0.0, 0.7750078889239508, 0.9667828583145376, 0.5551020408163265, 0.9572072072072072, 0.9445559000547146, 0.7170184696569921, 0.9936687770743086, 0.7602591792656588]\n",
      "Mean precision: 0.765412881497213\n",
      "Std precision: 0.30928413529507853\n",
      "F1-score for each fold: [0.907113729043951, 0.9198860247829832, 0.985435002726069, 0.8270056992547128, 0.8823242980035708, 0.9309480401093891, 0.5532924658888668, 0.9853357773704383, 0.7366638441998308, 0.9236226742923334, 0.28907330567081607, 0.9722795370951827, 0.6387730391497377, nan, nan, 0.8360851063829787, 0.9631294045552038, 0.7054246812189323, 0.6157189424121695, 0.9299694738732268, 0.8192952703975881, 0.9745894272407877, 0.8539247963957719]\n",
      "Mean F1-score: 0.8214233590506924\n",
      "Std F1-score: 0.17292270243695976\n"
     ]
    }
   ],
   "source": [
    "score_reporter(results, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be5e6676-c3d3-4a26-b0b8-88b50c1f599a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with 1 different parameter combinations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a05d62e8624d75af04adf9b4dc7f1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random Forest\n",
    "folder = './joblib_memmap'\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "dump(X, os.path.join(folder, 'X'))\n",
    "X_memmap = load(os.path.join(folder, 'X'), mmap_mode='r')\n",
    "dump(y, os.path.join(folder, 'y'))\n",
    "y_memmap = load(os.path.join(folder, 'y'), mmap_mode='r')\n",
    "\n",
    "#num_combinations = 30\n",
    "params = {\n",
    "    \"n_estimators\": [300],\n",
    "    \"max_depth\": [30]\n",
    "}\n",
    "param_grid = ParameterGrid(params)\n",
    "print(f'Fitting with {len(param_grid)} different parameter combinations')\n",
    "results = {}\n",
    "\n",
    "with tqdm(param_grid) as pbar:\n",
    "    for fit_params in pbar:\n",
    "        pbar.set_description(f'Fitting parameter combination: {fit_params}')\n",
    "        \n",
    "        clf = RandomForestClassifier(**fit_params)\n",
    "        \n",
    "        fold_results = []\n",
    "        for (train, test) in tqdm(splits, leave=False):\n",
    "            X_train = X.iloc[train]\n",
    "            y_train = y.iloc[train]\n",
    "\n",
    "            X_test = X.iloc[test]\n",
    "            y_test = y.iloc[test]\n",
    "\n",
    "            cloned_clf = clone(clf)\n",
    "            cloned_clf.fit(X_train.astype(np.float32), y_train.astype(np.float32))\n",
    "\n",
    "            pred_values = cloned_clf.predict(X_test)\n",
    "\n",
    "            cm = confusion_matrix(y_test.values.reshape(y_test.shape[0]), pred_values)\n",
    "            sensitivity = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "            specificity = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "            precision = (cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "\n",
    "            results_dict = {\n",
    "                \"accuracy\": accuracy_score(y_test, pred_values),\n",
    "                \"sensitivity\": sensitivity,\n",
    "                \"specificity\": specificity,\n",
    "                \"precision\": precision,\n",
    "                \"f1_score\": (2*precision*sensitivity)/(precision+sensitivity)\n",
    "            }\n",
    "\n",
    "            fold_results.append(results_dict)\n",
    "        \n",
    "        current_results = {}\n",
    "        for i, result in enumerate(fold_results):\n",
    "            current_results[f\"split{i}_accuracy\"] = result[\"accuracy\"]\n",
    "            current_results[f\"split{i}_sensitivity\"] = result[\"sensitivity\"]\n",
    "            current_results[f\"split{i}_specificity\"] = result[\"specificity\"]\n",
    "            current_results[f\"split{i}_precision\"] = result[\"precision\"]\n",
    "            current_results[f\"split{i}_f1_score\"] = result[\"f1_score\"]\n",
    "        results[tuple(sorted(fit_params.items()))] = current_results\n",
    "        results[tuple(sorted(fit_params.items()))]['folds'] = len(splits)\n",
    "\n",
    "with open(f'saved_results_{current_weight}/rf_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3bd4c1ca-dde4-4b2a-8a71-ff32d09b3f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('max_depth', 30), ('n_estimators', 300)) 0.8901043854219829\n",
      "The best parameters were (('max_depth', 30), ('n_estimators', 300))\n",
      "Accuracy for each fold: [0.8891319207108681, 0.954373361809533, 0.9825037707390648, 0.7247332959011791, 0.964200477326969, 0.9191240875912409, 0.7978031831427931, 0.9698805041741693, 0.8773960216998191, 0.8685427401241907, 0.9548577036310107, 0.9581821323656471, 0.7278867102396515, 0.8570334048421698, 0.8467830423940149, 0.9307511737089202, 0.9662307564972686, 0.8873004857737682, 0.5348813628067329, 0.9470137420718816, 0.9670105198651823, 0.9700996677740864, 0.9766807995154452]\n",
      "Mean accuracy: 0.8901043854219829\n",
      "Std accuracy: 0.10563645198724894\n",
      "Sensitivity for each fold: [0.887920298879203, 0.9639582272032603, 0.9826020015396458, 0.704452210910196, 0.9811656005685856, 0.9131649650725416, 0.7044763146458062, 0.9702596122247782, 0.8317686819376643, 0.8663967611336032, 0.677710843373494, 0.9599159810957465, 0.5075921908893709, nan, nan, 0.9072431633407243, 0.9713064713064713, 0.978067575577949, 0.39508809396689804, 0.9642793987621574, 0.9718681318681318, 0.9704986371653038, 0.9924901185770751]\n",
      "Mean sensitivity: 0.8620107276208858\n",
      "Std sensitivity: 0.16484896332159704\n",
      "Specificity for each fold: [0.9886363636363636, 0.9236423029808085, 0.9777777777777777, 0.9705340699815838, 0.9549251991451331, 0.9762886597938144, 0.830237124301465, 0.8695652173913043, 0.8989701704545454, 0.9685534591194969, 0.9652675642040955, 0.8243243243243243, 0.950109409190372, 0.8570334048421698, 0.8467830423940149, 0.9402940294029403, 0.9440993788819876, 0.8595505617977528, 0.9767932489451476, 0.8959749085206482, 0.9655401809473124, 0.9636363636363636, 0.9712581344902386]\n",
      "Mean specificity: 0.9269476041808548\n",
      "Std specificity: 0.052661701632926966\n",
      "Precision for each fold: [0.9998441882206295, 0.9758896338318721, 0.9995301487862177, 0.9965606190885641, 0.9224858002004678, 0.9973004694835681, 0.590528233151184, 0.9994922139471902, 0.795617816091954, 0.9992217898832685, 0.42293233082706766, 0.9976350736765508, 0.9112149532710281, 0.0, 0.0, 0.8604977216964599, 0.9869727047146402, 0.6804123711340206, 0.9817578772802653, 0.9647912243453645, 0.8951417004048583, 0.9976924344816219, 0.9221446933529196]\n",
      "Mean precision: 0.8216375651247702\n",
      "Std precision: 0.2923401342027043\n",
      "F1-score for each fold: [0.9405643092707952, 0.9698872373141979, 0.9909937888198758, 0.8254250867978279, 0.9509213018770449, 0.9533800841514727, 0.6424891002774475, 0.9846589961647491, 0.8132917202129613, 0.9280809541019154, 0.5208333333333334, 0.9784121320249776, 0.651992198383951, nan, nan, 0.8832523835222161, 0.979076923076923, 0.8025291828793775, 0.563433901208718, 0.9645352436543734, 0.9319283456269758, 0.9839076723016905, 0.9560251284980011]\n",
      "Mean F1-score: 0.8674104296904203\n",
      "Std F1-score: 0.14497844598608123\n"
     ]
    }
   ],
   "source": [
    "score_reporter(results, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ea1d458-c374-4aa5-9580-db049b126f8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with 1 different parameter combinations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c455c2f47ecf4a34831dd6414e6e6f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# AdaBoost\n",
    "folder = './joblib_memmap'\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "dump(X, os.path.join(folder, 'X'))\n",
    "X_memmap = load(os.path.join(folder, 'X'), mmap_mode='r')\n",
    "dump(y, os.path.join(folder, 'y'))\n",
    "y_memmap = load(os.path.join(folder, 'y'), mmap_mode='r')\n",
    "\n",
    "#num_combinations = 30\n",
    "params = {\n",
    "    \"n_estimators\": [300]\n",
    "}\n",
    "param_grid = ParameterGrid(params)\n",
    "print(f'Fitting with {len(param_grid)} different parameter combinations')\n",
    "results = {}\n",
    "\n",
    "with tqdm(param_grid) as pbar:\n",
    "    for fit_params in pbar:\n",
    "        pbar.set_description(f'Fitting parameter combination: {fit_params}')\n",
    "        \n",
    "        clf = AdaBoostClassifier(algorithm=\"SAMME.R\",\n",
    "                                **fit_params)\n",
    "        fold_results = Parallel(n_jobs=4)(\n",
    "            delayed(fit_xgboost_parallel)(clf, X_memmap, y_memmap, train, test, **fit_params)\n",
    "            for (train, test) in splits\n",
    "        )\n",
    "        \n",
    "        current_results = {}\n",
    "        for i, result in enumerate(fold_results):\n",
    "            current_results[f\"split{i}_accuracy\"] = result[\"accuracy\"]\n",
    "            current_results[f\"split{i}_sensitivity\"] = result[\"sensitivity\"]\n",
    "            current_results[f\"split{i}_specificity\"] = result[\"specificity\"]\n",
    "            current_results[f\"split{i}_precision\"] = result[\"precision\"]\n",
    "            current_results[f\"split{i}_f1_score\"] = result[\"f1_score\"]\n",
    "            current_results[f\"split{i}_feature_importances\"] = result[\"feature_importances\"]\n",
    "        results[tuple(sorted(fit_params.items()))] = current_results\n",
    "        results[tuple(sorted(fit_params.items()))]['folds'] = len(splits)\n",
    "\n",
    "with open(f'saved_results_{current_weight}/ada_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f52a866f-43d5-4276-9f1a-5a1382a1389f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('n_estimators', 300),) 0.8805209704558556\n",
      "The best parameters were (('n_estimators', 300),)\n",
      "Accuracy for each fold: [0.8702665755297334, 0.9486457625473255, 0.9742081447963801, 0.6734980348119034, 0.9679688481346564, 0.9045255474452555, 0.8174176193678547, 0.9759371419217547, 0.875708257986739, 0.8034086405073325, 0.9605277505179369, 0.9324347675825125, 0.7181917211328976, 0.8331290223720502, 0.8932668329177057, 0.9334186939820742, 0.9466975666280417, 0.8977099236641222, 0.4980734131007909, 0.944899577167019, 0.9652742314370341, 0.9420114768951978, 0.9747627700383605]\n",
      "Mean accuracy: 0.8805209704558556\n",
      "Std accuracy: 0.11406440145173613\n",
      "Sensitivity for each fold: [0.8689636086896361, 0.9610290371879776, 0.9741339491916859, 0.6479258471356937, 0.9676616915422885, 0.8973670069854917, 0.7031725336810083, 0.9763391390075583, 0.7870822380773563, 0.7997300944669365, 0.6807228915662651, 0.9338351129004026, 0.4822125813449024, nan, nan, 0.8839615668883961, 0.9456654456654456, 0.945465323058684, 0.3482381206620395, 0.9543766578249336, 0.9569230769230769, 0.9411576078242745, 0.9790513833992095]\n",
      "Mean sensitivity: 0.8397626149534887\n",
      "Std sensitivity: 0.17130429721496046\n",
      "Specificity for each fold: [0.9772727272727273, 0.9089424254797877, 0.9777777777777777, 0.9834254143646409, 0.9681367787060423, 0.9731958762886598, 0.8571212807732971, 0.8695652173913043, 0.9176136363636364, 0.9748427672955975, 0.9710374476750764, 0.8243243243243243, 0.9562363238512035, 0.8331290223720502, 0.8932668329177057, 0.9534953495349535, 0.9511978704525288, 0.88310982239942, 0.9717299578059072, 0.9168844746471511, 0.967802022352315, 0.9558441558441558, 0.9732917570498916]\n",
      "Mean specificity: 0.9330105766495719\n",
      "Std specificity: 0.0490840308614492\n",
      "Precision for each fold: [0.9996816300541229, 0.9712961771141717, 0.999526066350711, 0.9978937514626726, 0.943193626602009, 0.9968958930276982, 0.6310452418096724, 0.9994953742640875, 0.81875, 0.9993254637436763, 0.46887966804979253, 0.9975691847419597, 0.9174576970697482, 0.0, 0.0, 0.8852701702442635, 0.9883028498511272, 0.7120535714285714, 0.9749626307922272, 0.9713822894168467, 0.8999586606035552, 0.9971122812977747, 0.9263275991024682]\n",
      "Mean precision: 0.8302773837837895\n",
      "Std precision: 0.28836295467142964\n",
      "F1-score for each fold: [0.9297505366792509, 0.9661353306446451, 0.9866666666666667, 0.7857011240095817, 0.9552710050868269, 0.9445167128556078, 0.6651593011305241, 0.987781564292245, 0.8026038675090944, 0.888455772113943, 0.5552825552825552, 0.9646505740891421, 0.6321626617375231, nan, nan, 0.8846153846153846, 0.966514143094842, 0.8123249299719888, 0.5131785995279308, 0.9628043885469628, 0.9275671069450362, 0.9683272847245133, 0.9519600307455803]\n",
      "Mean F1-score: 0.8595918828699928\n",
      "Std F1-score: 0.14439608625954026\n",
      "Average feature importances: \n",
      "{'S': 0.01753623188405797, 't': 0.008405797101449274, 'o': 0.013913043478260867}\n"
     ]
    }
   ],
   "source": [
    "score_reporter(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a46da264-3e41-4b8e-a668-94f630144eab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Gradient Boost\\nfolder = \\'./joblib_memmap\\'\\ntry:\\n    os.mkdir(folder)\\nexcept FileExistsError:\\n    pass\\n\\ndump(X, os.path.join(folder, \\'X\\'))\\nX_memmap = load(os.path.join(folder, \\'X\\'), mmap_mode=\\'r\\')\\ndump(y, os.path.join(folder, \\'y\\'))\\ny_memmap = load(os.path.join(folder, \\'y\\'), mmap_mode=\\'r\\')\\n\\n#num_combinations = 30\\nparams = {\\n    \"n_estimators\": [350]\\n}\\nparam_grid = ParameterGrid(params)\\nprint(f\\'Fitting with {len(param_grid)} different parameter combinations\\')\\nresults = {}\\n\\nwith tqdm(param_grid) as pbar:\\n    for fit_params in pbar:\\n        pbar.set_description(f\\'Fitting parameter combination: {fit_params}\\')\\n        \\n        clf = GradientBoostingClassifier(loss=\"log_loss\",\\n                                         max_depth=8,\\n                                            **fit_params)\\n        fold_results = Parallel(n_jobs=4)(\\n            delayed(fit_xgboost_parallel)(clf, X_memmap, y_memmap, train, test, **fit_params)\\n            for (train, test) in splits\\n        )\\n        \\n        current_results = {}\\n        for i, result in enumerate(fold_results):\\n            current_results[f\"split{i}_accuracy\"] = result[\"accuracy\"]\\n            current_results[f\"split{i}_sensitivity\"] = result[\"sensitivity\"]\\n            current_results[f\"split{i}_specificity\"] = result[\"specificity\"]\\n            current_results[f\"split{i}_precision\"] = result[\"precision\"]\\n            current_results[f\"split{i}_f1_score\"] = result[\"f1_score\"]\\n            current_results[f\"split{i}_feature_importances\"] = result[\"feature_importances\"]\\n        results[tuple(sorted(fit_params.items()))] = current_results\\n        results[tuple(sorted(fit_params.items()))][\\'folds\\'] = len(splits)\\n\\nwith open(f\\'saved_results_{current_weight}/gb_results.pickle\\', \\'wb\\') as handle:\\n    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Gradient Boost\n",
    "folder = './joblib_memmap'\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "dump(X, os.path.join(folder, 'X'))\n",
    "X_memmap = load(os.path.join(folder, 'X'), mmap_mode='r')\n",
    "dump(y, os.path.join(folder, 'y'))\n",
    "y_memmap = load(os.path.join(folder, 'y'), mmap_mode='r')\n",
    "\n",
    "#num_combinations = 30\n",
    "params = {\n",
    "    \"n_estimators\": [350]\n",
    "}\n",
    "param_grid = ParameterGrid(params)\n",
    "print(f'Fitting with {len(param_grid)} different parameter combinations')\n",
    "results = {}\n",
    "\n",
    "with tqdm(param_grid) as pbar:\n",
    "    for fit_params in pbar:\n",
    "        pbar.set_description(f'Fitting parameter combination: {fit_params}')\n",
    "        \n",
    "        clf = GradientBoostingClassifier(loss=\"log_loss\",\n",
    "                                         max_depth=8,\n",
    "                                            **fit_params)\n",
    "        fold_results = Parallel(n_jobs=4)(\n",
    "            delayed(fit_xgboost_parallel)(clf, X_memmap, y_memmap, train, test, **fit_params)\n",
    "            for (train, test) in splits\n",
    "        )\n",
    "        \n",
    "        current_results = {}\n",
    "        for i, result in enumerate(fold_results):\n",
    "            current_results[f\"split{i}_accuracy\"] = result[\"accuracy\"]\n",
    "            current_results[f\"split{i}_sensitivity\"] = result[\"sensitivity\"]\n",
    "            current_results[f\"split{i}_specificity\"] = result[\"specificity\"]\n",
    "            current_results[f\"split{i}_precision\"] = result[\"precision\"]\n",
    "            current_results[f\"split{i}_f1_score\"] = result[\"f1_score\"]\n",
    "            current_results[f\"split{i}_feature_importances\"] = result[\"feature_importances\"]\n",
    "        results[tuple(sorted(fit_params.items()))] = current_results\n",
    "        results[tuple(sorted(fit_params.items()))]['folds'] = len(splits)\n",
    "\n",
    "with open(f'saved_results_{current_weight}/gb_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b6f6d7b-36f0-45bc-be7d-6fd5d3376315",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# score_reporter(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b677a7d-c3d7-47e5-83e8-9e8035b78416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with 1 different parameter combinations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c665f527224a495185d1cc043586697d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SVC\n",
    "folder = './joblib_memmap'\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "dump(X, os.path.join(folder, 'X'))\n",
    "X_memmap = load(os.path.join(folder, 'X'), mmap_mode='r')\n",
    "dump(y, os.path.join(folder, 'y'))\n",
    "y_memmap = load(os.path.join(folder, 'y'), mmap_mode='r')\n",
    "\n",
    "#num_combinations = 30\n",
    "params = {\n",
    "    #\"kernel\": [\"linear\", \"rbf\"]\n",
    "    \"verbose\": [False]\n",
    "}\n",
    "param_grid = ParameterGrid(params)\n",
    "print(f'Fitting with {len(param_grid)} different parameter combinations')\n",
    "results = {}\n",
    "\n",
    "with tqdm(param_grid) as pbar:\n",
    "    for fit_params in pbar:\n",
    "        pbar.set_description(f'Fitting parameter combination: {fit_params}')\n",
    "        \n",
    "        clf = LinearSVC(**fit_params)\n",
    "        \n",
    "        fold_results = []\n",
    "        for (train, test) in tqdm(splits, leave=False):\n",
    "            X_train = X.iloc[train]\n",
    "            y_train = y.iloc[train]\n",
    "\n",
    "            X_test = X.iloc[test]\n",
    "            y_test = y.iloc[test]\n",
    "\n",
    "            cloned_clf = clone(clf)\n",
    "            cloned_clf.fit(X_train, y_train)\n",
    "\n",
    "            pred_values = cloned_clf.predict(X_test)\n",
    "\n",
    "            cm = confusion_matrix(y_test.values.reshape(y_test.shape[0]), pred_values)\n",
    "            sensitivity = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "            specificity = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "            precision = (cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "\n",
    "            results_dict = {\n",
    "                \"accuracy\": accuracy_score(y_test, pred_values),\n",
    "                \"sensitivity\": sensitivity,\n",
    "                \"specificity\": specificity,\n",
    "                \"precision\": precision,\n",
    "                \"f1_score\": (2*precision*sensitivity)/(precision+sensitivity)\n",
    "            }\n",
    "\n",
    "            fold_results.append(results_dict)\n",
    "        \n",
    "        current_results = {}\n",
    "        for i, result in enumerate(fold_results):\n",
    "            current_results[f\"split{i}_accuracy\"] = result[\"accuracy\"]\n",
    "            current_results[f\"split{i}_sensitivity\"] = result[\"sensitivity\"]\n",
    "            current_results[f\"split{i}_specificity\"] = result[\"specificity\"]\n",
    "            current_results[f\"split{i}_precision\"] = result[\"precision\"]\n",
    "            current_results[f\"split{i}_f1_score\"] = result[\"f1_score\"]\n",
    "        results[tuple(sorted(fit_params.items()))] = current_results\n",
    "        results[tuple(sorted(fit_params.items()))]['folds'] = len(splits)\n",
    "\n",
    "with open(f'saved_results_{current_weight}/svc_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe0d73f7-0b7f-4602-8a74-691bed4a524e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('verbose', False),) 0.8118963745224512\n",
      "The best parameters were (('verbose', False),)\n",
      "Accuracy for each fold: [0.8854408749145591, 0.8810795068439957, 0.9668174962292609, 0.722206625491297, 0.8758949880668258, 0.9045255474452555, 0.7974669356646492, 0.9435259453265673, 0.7654008438818566, 0.7798916633637204, 0.8365499945480318, 0.9063418005875238, 0.6749455337690632, 0.8974869751762182, 0.3403491271820449, 0.7440247545881349, 0.9119351100811124, 0.8473282442748091, 0.5960251470290002, 0.8673361522198731, 0.8450617914411194, 0.8881002718212021, 0.7958812840702605]\n",
      "Mean accuracy: 0.8118963745224512\n",
      "Std accuracy: 0.13291212352509207\n",
      "Sensitivity for each fold: [0.887920298879203, 0.9659959246051961, 0.9712086220169361, 0.7199513751709467, 0.9573560767590619, 0.9288554540569586, 0.9439374185136897, 0.9441340782122905, 0.8527975966954563, 0.777867746288799, 0.6897590361445783, 0.9100297566952564, 0.6188720173535792, nan, nan, 0.9368070953436807, 0.9194139194139194, 0.9347954949614701, 0.5654030966364122, 0.9490716180371352, 0.9463736263736263, 0.8981882315215649, 0.9664031620553359]\n",
      "Mean sensitivity: 0.8707210307492904\n",
      "Std sensitivity: 0.11879066017222793\n",
      "Specificity for each fold: [0.6818181818181818, 0.6088199265006125, 0.7555555555555555, 0.7495395948434622, 0.8313580726636876, 0.6711340206185566, 0.7465639631475608, 0.782608695652174, 0.7240767045454546, 0.8742138364779874, 0.8420635818531508, 0.6216216216216216, 0.7315098468271335, 0.8974869751762182, 0.3403491271820449, 0.6657665766576658, 0.8793256433007985, 0.8205871692642261, 0.6928270042194092, 0.6257187663355985, 0.8143959552953699, 0.7246753246753247, 0.7373915401301518]\n",
      "Mean specificity: 0.7312785949722584\n",
      "Std specificity: 0.1168229938334212\n",
      "Precision for each fold: [0.995655546935609, 0.8878614069998829, 0.994795773537297, 0.9720968403775133, 0.7563166760247052, 0.9644052666815442, 0.5641558441558442, 0.9991305859850461, 0.5937254901960785, 0.9965421853388658, 0.14092307692307693, 0.9946431987755883, 0.6992647058823529, 0.0, 0.0, 0.5322275876548394, 0.9707778255264289, 0.6143358005453837, 0.8533440773569702, 0.8822949202696038, 0.6068207440811725, 0.9814295725297828, 0.557964399817435]\n",
      "Mean precision: 0.7199439793736966\n",
      "Std precision: 0.3098201774069997\n",
      "F1-score for each fold: [0.9387068461088355, 0.925282098200671, 0.9828607042692428, 0.8272370144041904, 0.8450439146800501, 0.9462966004269995, 0.70622662981629, 0.9708541015459998, 0.7000616522811344, 0.8737304835531303, 0.2340316811446091, 0.9504570383912248, 0.6566168009205984, nan, nan, 0.678805730352122, 0.9443979933110368, 0.7414198401504467, 0.6801541425818882, 0.9144658374510137, 0.739481366992959, 0.9379656760150691, 0.7074652777777778]\n",
      "Mean F1-score: 0.8048362585892994\n",
      "Std F1-score: 0.169968598760441\n"
     ]
    }
   ],
   "source": [
    "score_reporter(results, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec666c6c",
   "metadata": {
    "papermill": {
     "duration": 1591.980319,
     "end_time": "2023-02-25T02:46:48.217383",
     "exception": false,
     "start_time": "2023-02-25T02:20:16.237064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with 1 different parameter combinations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d70b52ff8d84b1493cae2c0c5b68c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# XGBoost\n",
    "folder = './joblib_memmap'\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "dump(X, os.path.join(folder, 'X'))\n",
    "X_memmap = load(os.path.join(folder, 'X'), mmap_mode='r')\n",
    "dump(y, os.path.join(folder, 'y'))\n",
    "y_memmap = load(os.path.join(folder, 'y'), mmap_mode='r')\n",
    "\n",
    "#num_combinations = 30\n",
    "params = {\n",
    "    \"n_estimators\": [1050],\n",
    "    \"max_depth\": [4]\n",
    "}\n",
    "param_grid = ParameterGrid(params)\n",
    "print(f'Fitting with {len(param_grid)} different parameter combinations')\n",
    "results = {}\n",
    "\n",
    "with tqdm(param_grid) as pbar:\n",
    "    for fit_params in pbar:\n",
    "        pbar.set_description(f'Fitting parameter combination: {fit_params}')\n",
    "        \n",
    "        clf = XGBClassifier(learning_rate = 0.1,\n",
    "                        verbose=None, \n",
    "                        eval_metric='logloss',\n",
    "                        tree_method='gpu_hist',\n",
    "                        **fit_params)\n",
    "        fold_results = Parallel(n_jobs=8)(\n",
    "            delayed(fit_xgboost_parallel)(clf, X_memmap, y_memmap, train, test, **fit_params)\n",
    "            for (train, test) in splits\n",
    "        )\n",
    "        \n",
    "        current_results = {}\n",
    "        for i, result in enumerate(fold_results):\n",
    "            current_results[f\"split{i}_accuracy\"] = result[\"accuracy\"]\n",
    "            current_results[f\"split{i}_sensitivity\"] = result[\"sensitivity\"]\n",
    "            current_results[f\"split{i}_specificity\"] = result[\"specificity\"]\n",
    "            current_results[f\"split{i}_precision\"] = result[\"precision\"]\n",
    "            current_results[f\"split{i}_f1_score\"] = result[\"f1_score\"]\n",
    "            current_results[f\"split{i}_feature_importances\"] = result[\"feature_importances\"]\n",
    "        results[tuple(sorted(fit_params.items()))] = current_results\n",
    "        results[tuple(sorted(fit_params.items()))]['folds'] = len(splits)\n",
    "\n",
    "with open(f'saved_results_{current_weight}/xg_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb321053",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('max_depth', 4), ('n_estimators', 1050)) 0.8896594660834751\n",
      "The best parameters were (('max_depth', 4), ('n_estimators', 1050))\n",
      "Accuracy for each fold: [0.8888585099111415, 0.9495194641296961, 0.9838612368024132, 0.73385738349242, 0.9640748649667127, 0.904720194647202, 0.7834566240753195, 0.9806842363725651, 0.8795660036166365, 0.8711850971066191, 0.9552938610838513, 0.9585277345775013, 0.7327886710239652, 0.8437021146184492, 0.8724189526184538, 0.9489970123772941, 0.9615957622910114, 0.8741151977793199, 0.5344757655647941, 0.9256078224101479, 0.9679297313859667, 0.9702506795530051, 0.9766807995154452]\n",
      "Mean accuracy: 0.8896594660834751\n",
      "Std accuracy: 0.10532596210771614\n",
      "Sensitivity for each fold: [0.8876435588764355, 0.956698930208864, 0.9841416474210931, 0.7196474699893634, 0.9832977967306326, 0.8969371305749597, 0.5775749674054759, 0.9809398619783108, 0.8422831393165603, 0.8695006747638326, 0.6746987951807228, 0.9602660598634692, 0.5117136659436009, nan, nan, 0.9142645971914265, 0.9660154660154661, 0.980438648488441, 0.39375333689268555, 0.9301503094606542, 0.9753846153846154, 0.9711399711399712, 0.9924901185770751]\n",
      "Mean sensitivity: 0.8556657505430313\n",
      "Std sensitivity: 0.1712837332071498\n",
      "Specificity for each fold: [0.9886363636363636, 0.9265006124948959, 0.9703703703703703, 0.9060773480662984, 0.9535651836020983, 0.979381443298969, 0.8550067965564114, 0.9130434782608695, 0.8971946022727273, 0.949685534591195, 0.9658332390541916, 0.8243243243243243, 0.9557986870897155, 0.8437021146184492, 0.8724189526184538, 0.963096309630963, 0.9423247559893523, 0.8416092787241755, 0.9793248945147679, 0.9121798222686879, 0.9656732304417244, 0.9558441558441558, 0.9712581344902386]\n",
      "Mean specificity: 0.9275152014243215\n",
      "Std specificity: 0.048995497236326714\n",
      "Precision for each fold: [0.9998441396508728, 0.9765990639625585, 0.9993746091307066, 0.989346145811573, 0.9204923486360612, 0.9976093712646426, 0.580602883355177, 0.9996651038178165, 0.794826364280652, 0.998759882188808, 0.42585551330798477, 0.9976359338061466, 0.9211245607184694, 0.0, 0.0, 0.9095588235294118, 0.9864921030756443, 0.6542721518987342, 0.9836612204068023, 0.9690493736182756, 0.895841744045216, 0.9972011853803096, 0.9221446933529196]\n",
      "Mean precision: 0.8226068354451644\n",
      "Std precision: 0.29363616707347906\n",
      "F1-score for each fold: [0.9404090009528696, 0.9665465774575398, 0.9916996354045459, 0.8332160450387052, 0.9508591065292097, 0.9445984947088449, 0.5790849673202614, 0.9902139658318129, 0.8178669097538742, 0.9296587547795974, 0.522144522144522, 0.9785943631823046, 0.6579277646074467, nan, nan, 0.9119056395134537, 0.9761464116800329, 0.7848161328588374, 0.5623868077399676, 0.9492014797437517, 0.9339225589225589, 0.9839980505239218, 0.9560251284980011]\n",
      "Mean F1-score: 0.8648201103424791\n",
      "Std F1-score: 0.14972564476620107\n",
      "Average feature importances: \n",
      "{'S': 0.033234593, 't': 0.02166846, 'o': 0.13290298}\n"
     ]
    }
   ],
   "source": [
    "score_reporter(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1726e419",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with 1 different parameter combinations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959fd2b8cc9f4895ad56ec64beef9fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% gpu memory available for training. Free: 2842 Total: 7979.3125\n",
      "Warning: less than 75% gpu memory available for training. Free: 2842 Total: 7979.3125\n",
      "Warning: less than 75% gpu memory available for training. Free: 2842 Total: 7979.3125\n",
      "Warning: less than 75% gpu memory available for training. Free: 2844 Total: 7979.3125\n",
      "Warning: less than 75% gpu memory available for training. Free: 2844.4375 Total: 7979.3125\n",
      "Warning: less than 75% gpu memory available for training. Free: 2844.4375 Total: 7979.3125\n",
      "Warning: less than 75% gpu memory available for training. Free: 2844.4375 Total: 7979.3125\n",
      "Warning: less than 75% gpu memory available for training. Free: 2844.4375 Total: 7979.3125\n",
      "Warning: less than 75% gpu memory available for training. Free: 2844.4375 Total: 7979.3125\n",
      "Warning: less than 75% gpu memory available for training. Free: 2844.3125 Total: 7979.3125\n",
      "Warning: less than 75% gpu memory available for training. Free: 2844.3125 Total: 7979.3125\n",
      "Warning: less than 75% gpu memory available for training. Free: 2844.375 Total: 7979.3125\n",
      "Warning: less than 75% gpu memory available for training. Free: 2844.375 Total: 7979.3125\n",
      "Warning: less than 75% gpu memory available for training. Free: 2844.375 Total: 7979.3125\n",
      "Warning: less than 75% gpu memory available for training. Free: 2844.375 Total: 7979.3125\n",
      "Warning: less than 75% gpu memory available for training. Free: 2844.375 Total: 7979.3125\n",
      "Warning: less than 75% gpu memory available for training. Free: 2844.4375 Total: 7979.3125\n",
      "Warning: less than 75% gpu memory available for training. Free: 2844.4375 Total: 7979.3125\n",
      "Warning: less than 75% gpu memory available for training. Free: 2844.4375 Total: 7979.3125\n",
      "Warning: less than 75% gpu memory available for training. Free: 2844.4375 Total: 7979.3125\n",
      "Warning: less than 75% gpu memory available for training. Free: 2844.4375 Total: 7979.3125\n",
      "Warning: less than 75% gpu memory available for training. Free: 2844.4375 Total: 7979.3125\n",
      "Warning: less than 75% gpu memory available for training. Free: 2844.4375 Total: 7979.3125\n"
     ]
    }
   ],
   "source": [
    "# CatBoost\n",
    "folder = './joblib_memmap'\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "dump(X, os.path.join(folder, 'X'))\n",
    "X_memmap = load(os.path.join(folder, 'X'), mmap_mode='r')\n",
    "dump(y, os.path.join(folder, 'y'))\n",
    "y_memmap = load(os.path.join(folder, 'y'), mmap_mode='r')\n",
    "\n",
    "#num_combinations = 15\n",
    "params = {\n",
    "    \"n_estimators\": [650],\n",
    "    \"max_depth\": [6]\n",
    "}\n",
    "param_grid = ParameterGrid(params)\n",
    "print(f'Fitting with {len(param_grid)} different parameter combinations')\n",
    "results = {}\n",
    "\n",
    "with tqdm(param_grid) as pbar:\n",
    "    for fit_params in pbar:\n",
    "        pbar.set_description(f'Fitting parameter combination: {fit_params}')\n",
    "        \n",
    "        clf = CatBoostClassifier(\n",
    "                        learning_rate=0.1,\n",
    "                        loss_function='Logloss',\n",
    "                        task_type=\"GPU\",\n",
    "                        silent=True,\n",
    "                        **fit_params)\n",
    "        fold_results = Parallel(n_jobs=1)(\n",
    "            delayed(fit_catboost_parallel)(clf, X_memmap, y_memmap, train, test, **fit_params)\n",
    "            for (train, test) in splits\n",
    "        )\n",
    "        \n",
    "        current_results = {}\n",
    "        for i, result in enumerate(fold_results):\n",
    "            current_results[f\"split{i}_accuracy\"] = result[\"accuracy\"]\n",
    "            current_results[f\"split{i}_sensitivity\"] = result[\"sensitivity\"]\n",
    "            current_results[f\"split{i}_specificity\"] = result[\"specificity\"]\n",
    "            current_results[f\"split{i}_precision\"] = result[\"precision\"]\n",
    "            current_results[f\"split{i}_f1_score\"] = result[\"f1_score\"]\n",
    "            current_results[f\"split{i}_feature_importances\"] = result[\"feature_importances\"]\n",
    "        results[tuple(sorted(fit_params.items()))] = current_results\n",
    "        results[tuple(sorted(fit_params.items()))]['folds'] = len(splits)\n",
    "\n",
    "with open(f'saved_results_{current_weight}/cb_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64aa7c72",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('max_depth', 6), ('n_estimators', 650)) 0.8925980023811104\n",
      "The best parameters were (('max_depth', 6), ('n_estimators', 650))\n",
      "Accuracy for each fold: [0.8900888585099112, 0.9522376468304048, 0.9852187028657617, 0.7356822010106682, 0.9662102750910689, 0.9104622871046228, 0.7911903160726295, 0.9813390080209526, 0.8802893309222423, 0.8779231074118113, 0.9550757823574311, 0.9606013478486263, 0.7305010893246188, 0.8496782102359791, 0.870423940149626, 0.9484635083226632, 0.9672239695414666, 0.8799444829979182, 0.5253498276211722, 0.9532241014799154, 0.9702788274946379, 0.9693446088794926, 0.979002624671916]\n",
      "Mean accuracy: 0.8925980023811104\n",
      "Std accuracy: 0.1073295775282797\n",
      "Sensitivity for each fold: [0.8888888888888888, 0.9620478858889455, 0.9852193995381062, 0.71934356480778, 0.9840085287846482, 0.9033852767329393, 0.6510212950890917, 0.9817614196516595, 0.8385279759669546, 0.87638326585695, 0.677710843373494, 0.9621914930859443, 0.5108459869848156, nan, nan, 0.9087213599408721, 0.9727309727309728, 0.979845880260818, 0.38160704751735186, 0.9671087533156498, 0.9736263736263736, 0.9701779701779701, 0.9936758893280633]\n",
      "Mean sensitivity: 0.8613728605499186\n",
      "Std sensitivity: 0.16923331503208874\n",
      "Specificity for each fold: [0.9886363636363636, 0.9207839934667211, 0.9851851851851852, 0.9337016574585635, 0.9564795026228872, 0.9783505154639175, 0.839903337864371, 0.8695652173913043, 0.9000355113636364, 0.949685534591195, 0.9654938341441339, 0.8378378378378378, 0.9520787746170678, 0.8496782102359791, 0.870423940149626, 0.9645964596459646, 0.9432120674356699, 0.8494019572308807, 0.979746835443038, 0.9121798222686879, 0.9692655667908462, 0.9558441558441558, 0.9739696312364425]\n",
      "Mean specificity: 0.9280893874749772\n",
      "Std specificity: 0.050059663173996696\n",
      "Precision for each fold: [0.9998443579766537, 0.9749612803304079, 0.9996875488204968, 0.9924528301886792, 0.925158703641831, 0.9975080099679601, 0.5856137607505864, 0.9994981599197056, 0.7986409155937053, 0.9987696093509689, 0.42452830188679247, 0.9978217462334362, 0.914918414918415, 0.0, 0.0, 0.912430426716141, 0.9867877786952931, 0.6654589371980676, 0.9834881320949432, 0.9701969132517296, 0.9055600981193785, 0.9971984179301252, 0.9290465631929047]\n",
      "Mean precision: 0.8243291698599226\n",
      "Std precision: 0.2935586105074278\n",
      "F1-score for each fold: [0.9411075300322298, 0.9684615384615384, 0.9924007444168735, 0.8341115320236103, 0.9536765972102635, 0.948116399729303, 0.6165877752623997, 0.9905503978779839, 0.8180985528485071, 0.9335825186889016, 0.5220417633410672, 0.9796827659953663, 0.6556236080178174, nan, nan, 0.910572116274764, 0.9797089567534332, 0.7926156796931191, 0.5498605635157228, 0.9686503719447397, 0.9383605168396527, 0.9835026412027632, 0.9602750190985485]\n",
      "Mean F1-score: 0.8684565518680287\n",
      "Std F1-score: 0.14900002527095646\n",
      "Average feature importances: \n",
      "{'S': 1.6795248220107808, 't': 1.38693377074104, 'o': 1.8130221332109067}\n"
     ]
    }
   ],
   "source": [
    "score_reporter(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e57665d-40dd-4c73-a1da-060a9968fa73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with 6 different parameter combinations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ced9363efc413b96acd40675e70998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LightGBM\n",
    "folder = './joblib_memmap'\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "dump(X, os.path.join(folder, 'X'))\n",
    "X_memmap = load(os.path.join(folder, 'X'), mmap_mode='r')\n",
    "dump(y, os.path.join(folder, 'y'))\n",
    "y_memmap = load(os.path.join(folder, 'y'), mmap_mode='r')\n",
    "\n",
    "#num_combinations = 15\n",
    "params = {\n",
    "    \"n_estimators\": np.arange(900, 1200, 50),\n",
    "    \"max_depth\": [5]\n",
    "}\n",
    "param_grid = ParameterGrid(params)\n",
    "print(f'Fitting with {len(param_grid)} different parameter combinations')\n",
    "results = {}\n",
    "\n",
    "with tqdm(param_grid) as pbar:\n",
    "    for fit_params in pbar:\n",
    "        pbar.set_description(f'Fitting parameter combination: {fit_params}')\n",
    "        \n",
    "        clf = lightgbm.LGBMClassifier(\n",
    "                        learning_rate=0.1,\n",
    "                        device=\"gpu\",\n",
    "                        verbose=-1,\n",
    "                        **fit_params)\n",
    "        fold_results = []\n",
    "        for (train, test) in tqdm(splits, leave=False):\n",
    "            X_train = X.iloc[train]\n",
    "            y_train = y.iloc[train]\n",
    "\n",
    "            X_test = X.iloc[test]\n",
    "            y_test = y.iloc[test]\n",
    "\n",
    "            cloned_clf = clone(clf)\n",
    "            cloned_clf.fit(X_train,y_train,eval_set=[(X_test,y_test),(X_train,y_train)], \n",
    "                   eval_metric='logloss')\n",
    "\n",
    "            pred_values = cloned_clf.predict(X_test)\n",
    "\n",
    "            cm = confusion_matrix(y_test.values.reshape(y_test.shape[0]), pred_values)\n",
    "            sensitivity = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "            specificity = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "            precision = (cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "\n",
    "            results_dict = {\n",
    "                \"accuracy\": accuracy_score(y_test, pred_values),\n",
    "                \"sensitivity\": sensitivity,\n",
    "                \"specificity\": specificity,\n",
    "                \"precision\": precision,\n",
    "                \"f1_score\": (2*precision*sensitivity)/(precision+sensitivity),\n",
    "                \"feature_importances\": {A: B for A, B in zip(cloned_clf.feature_name_, cloned_clf.feature_importances_)}\n",
    "            }\n",
    "\n",
    "            fold_results.append(results_dict)\n",
    "        \n",
    "        current_results = {}\n",
    "        for i, result in enumerate(fold_results):\n",
    "            current_results[f\"split{i}_accuracy\"] = result[\"accuracy\"]\n",
    "            current_results[f\"split{i}_sensitivity\"] = result[\"sensitivity\"]\n",
    "            current_results[f\"split{i}_specificity\"] = result[\"specificity\"]\n",
    "            current_results[f\"split{i}_precision\"] = result[\"precision\"]\n",
    "            current_results[f\"split{i}_f1_score\"] = result[\"f1_score\"]\n",
    "            current_results[f\"split{i}_feature_importances\"] = result[\"feature_importances\"]\n",
    "        results[tuple(sorted(fit_params.items()))] = current_results\n",
    "        results[tuple(sorted(fit_params.items()))]['folds'] = len(splits)\n",
    "\n",
    "with open(f'saved_results_{current_weight}/lg_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "140bf673-8b2b-4398-bf95-6e68c4c3ac38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('max_depth', 5), ('n_estimators', 900)) 0.8902554480407062\n",
      "(('max_depth', 5), ('n_estimators', 950)) 0.8902671429408384\n",
      "(('max_depth', 5), ('n_estimators', 1000)) 0.8900101982305616\n",
      "(('max_depth', 5), ('n_estimators', 1050)) 0.8899358732250775\n",
      "(('max_depth', 5), ('n_estimators', 1100)) 0.8895689985710263\n",
      "(('max_depth', 5), ('n_estimators', 1150)) 0.8899690825535622\n",
      "The best parameters were (('max_depth', 5), ('n_estimators', 950))\n",
      "Accuracy for each fold: [0.8898154477101845, 0.9491311523153092, 0.9834087481146304, 0.7344188658057271, 0.9629443537244065, 0.9067639902676399, 0.7833445415826048, 0.9787199214274022, 0.8784810126582279, 0.8791121680539041, 0.9544215461781703, 0.9593917401071367, 0.734640522875817, 0.8455409132699969, 0.8682294264339152, 0.9485702091335895, 0.9617612977983777, 0.8766134628730049, 0.5326505779760697, 0.9334038054968288, 0.9655806352772954, 0.9713077620054364, 0.9778921865536039]\n",
      "Mean accuracy: 0.8902671429408384\n",
      "Std accuracy: 0.1053912133840016\n",
      "Sensitivity for each fold: [0.8886121488861215, 0.9527508914926134, 0.9841416474210931, 0.7202552803525301, 0.9847192608386638, 0.8993014508328856, 0.5758365927857453, 0.978968123562274, 0.8437852046564025, 0.8774628879892038, 0.6536144578313253, 0.9609662173989147, 0.513882863340564, nan, nan, 0.9168514412416852, 0.968050468050468, 0.98221695317131, 0.3914842498665243, 0.9398762157382847, 0.9736263736263736, 0.9725829725829725, 0.991304347826087]\n",
      "Mean sensitivity: 0.8557280975948591\n",
      "Std sensitivity: 0.17288747453174044\n",
      "Specificity for each fold: [0.9886363636363636, 0.9375255206206615, 0.9481481481481482, 0.9060773480662984, 0.9510394404507481, 0.9783505154639175, 0.8554599003171727, 0.9130434782608695, 0.8948863636363636, 0.9559748427672956, 0.9657201040841724, 0.8378378378378378, 0.9573304157549234, 0.8455409132699969, 0.8682294264339152, 0.9614461446144614, 0.9343389529724934, 0.8443276549474448, 0.9789029535864979, 0.9142707788813382, 0.9631452900478978, 0.9506493506493506, 0.9732917570498916]\n",
      "Mean specificity: 0.9271379783260028\n",
      "Std specificity: 0.04690005935105413\n",
      "Precision for each fold: [0.9998443095126888, 0.9799580822635577, 0.9989060790748554, 0.989355040701315, 0.916639100231558, 0.9974967218977232, 0.5806310254163015, 0.9996644295302013, 0.7914758717858401, 0.9989245659855585, 0.4173076923076923, 0.9978189749182116, 0.9239469578783152, 0.0, 0.0, 0.9061358655953251, 0.9846822604015731, 0.6585850556438791, 0.9832383506537044, 0.9700675305712722, 0.8888443017656501, 0.9968775677896466, 0.9271719038817006]\n",
      "Mean precision: 0.8220683342524594\n",
      "Std precision: 0.29402953480165195\n",
      "F1-score for each fold: [0.940952380952381, 0.966162985922769, 0.9914689002636885, 0.8336264509321141, 0.9494603392153503, 0.945857352774952, 0.5782238708269692, 0.9892080358625269, 0.816793893129771, 0.9342625188591135, 0.5093896713615024, 0.9790459206419974, 0.6604404795093394, nan, nan, 0.9114621601763409, 0.9762955361723961, 0.7884844158934095, 0.5599999999999999, 0.9547332495060176, 0.9293056429620307, 0.9845804252556403, 0.9581661891117479]\n",
      "Mean F1-score: 0.8646628771109549\n",
      "Std F1-score: 0.15139687781865344\n",
      "Average feature importances: \n",
      "{'S': 222.30434782608697, 't': 186.34782608695653, 'o': 125.95652173913044}\n"
     ]
    }
   ],
   "source": [
    "score_reporter(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:afib]",
   "language": "python",
   "name": "conda-env-afib-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1605.834912,
   "end_time": "2023-02-25T02:46:48.296192",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-25T02:20:02.461280",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "a54746d825bf8111bf1bc1a45ca74b0568535c84e3a9f74f4e5d3cbe6ec0015b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
